{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "316cee81-fe85-44bf-be9b-0166e8d145f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "import random\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "import xml.etree.ElementTree as etree\n",
    "from itertools import combinations\n",
    "from matplotlib.path import Path\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71871b90-7297-4149-a446-50f08b30a5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_base = 'input/data'\n",
    "\n",
    "with open('input/data/train_all.json') as json_file:\n",
    "    train_json = json.load(json_file)\n",
    "    \n",
    "#class name    \n",
    "classes = {\"General_trash\":0, \"Paper\":1, \"Paper_pack\":2, \"Metal\":3, \"Glass\":4, \n",
    "           \"Plastic\":5, \"Styrofoam\":6, \"Plastic_bag\":7, \"Battery\":8, \"Clothing\":9}\n",
    "\n",
    "for i in classes.keys():\n",
    "    os.makedirs(os.path.join(dataset_base,'train_collage',i),exist_ok=True)\n",
    "    \n",
    "real_json = {}\n",
    "real_json['info'] = train_json['info']\n",
    "real_json['licenses'] = train_json['licenses']\n",
    "real_json['annotations'] = train_json['annotations']\n",
    "real_json['categories'] = train_json['categories']\n",
    "real_json['images'] =  train_json['images']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7c6f18-dcea-4f2e-a8d0-d4f7bf6cdbd8",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eb96fd6-8904-4c0f-aaed-cdefa5eb6cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segment_crop(img,tol=0, mask=None):\n",
    "    if mask is None:\n",
    "        mask = img > tol\n",
    "    return img[np.ix_(mask.any(1), mask.any(0))]\n",
    "\n",
    "def fill_mask(mask):\n",
    "\n",
    "    nx, ny = 512, 512\n",
    "    poly_verts = mask\n",
    "\n",
    "    # (<0,0> is at the top left of the grid)\n",
    "    x, y = np.meshgrid(np.arange(nx), np.arange(ny))\n",
    "    x, y = x.flatten(), y.flatten()\n",
    "\n",
    "    points = np.vstack((x,y)).T\n",
    "\n",
    "    path = Path(poly_verts)\n",
    "    grid = path.contains_points(points)\n",
    "    grid = grid.reshape((ny,nx))\n",
    "\n",
    "    return grid\n",
    "\n",
    "def turn_to_uint(a):\n",
    "    mask = np.zeros((512, 512), dtype=np.uint8)\n",
    "    for j in range(512):\n",
    "        for k in range(512):\n",
    "            if a[j][k]==False:\n",
    "                mask[j][k] = 0\n",
    "            else:\n",
    "                mask[j][k] = 255\n",
    "        \n",
    "    \n",
    "    return mask\n",
    "\n",
    "def make_ann(ann,mask,category_id):\n",
    "    for j in range(512):\n",
    "        for k in range(512):\n",
    "            if mask[j][k]==255:\n",
    "                ann[j][k] = category_id\n",
    "    return ann\n",
    "\n",
    "def get_bg_ann(background_img):\n",
    "    img_name = background_img[-8:-4]+'.png'\n",
    "    res = cv2.imread(os.path.join('/opt/ml/segmentation/moon/dataset/annotations/train',img_name))\n",
    "    # res = np.multiply(res, 20) # visualize위한 부분 실제로는 빼야됨\n",
    "\n",
    "    return res[:,:,0]\n",
    "\n",
    "\n",
    "# def get_bg_ann(background_img):\n",
    "#     img_name = background_img[-8:-4]+'.png'\n",
    "#     res = cv2.imread(os.path.join('/opt/ml/segmentation/moon/dataset/annotations/train',img_name))\n",
    "#     # res = np.multiply(res, 20) # visualize위한 부분 실제로는 빼야됨\n",
    "#     return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8e617ce-d3dd-423b-957f-9ede4afc9582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "2620\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1109/3290903586.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;31m#mask_t는 annotation 좌표 tuple로 저장한 list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;31m#mask : 좌표에 class값넣은것.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mturn_to_uint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1109/3446748567.py\u001b[0m in \u001b[0;36mfill_mask\u001b[0;34m(mask)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoly_verts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mny\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/segmentation/lib/python3.7/site-packages/matplotlib/path.py\u001b[0m in \u001b[0;36mcontains_points\u001b[0;34m(self, points, transform, radius)\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m             \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrozen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoints_in_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mradius\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bool'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 마스크 영상을 이용한 영상 합성\n",
    "\n",
    "pass_category=[4,6,10,11] # 합성에 사용하고 싶지 않은 catagory들\n",
    "background_img = ['/opt/ml/segmentation/moon/dataset/images/train/0007.jpg','/opt/ml/segmentation/moon/dataset/images/train/0147.jpg','/opt/ml/segmentation/moon/dataset/images/train/0156.jpg','/opt/ml/segmentation/moon/dataset/images/train/0133.jpg','/opt/ml/segmentation/moon/dataset/images/train/0131.jpg','/opt/ml/segmentation/moon/dataset/images/train/0030.jpg','/opt/ml/segmentation/moon/dataset/images/train/0086.jpg','/opt/ml/segmentation/moon/dataset/images/train/0138.jpg','/opt/ml/segmentation/moon/dataset/images/train/0664.jpg']\n",
    "adding_point=[(300,10),(20,200),(0,10),(256,256),(10,300),(100,200)]\n",
    "\n",
    "\n",
    "#annotations 겹치는 경우 어떻게 하는지, COCO에서는 다른그거에서는? 위에 있는거만 표시하는지??\n",
    "##bg ann 가져오는거 만들어야함 Done\n",
    "##하나의 이어져 있는 객체인지 확인해야함 Done\n",
    "\n",
    "idx = 0\n",
    "lala = 0\n",
    "im_id = 2617\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    if im_id == 4600:\n",
    "        break\n",
    "    for k in background_img:\n",
    "        im_cnt=0\n",
    "        bg_img = cv2.imread(k)\n",
    "        ann = get_bg_ann(k)\n",
    "        cv2.imwrite(f\"bg_test.png\",ann)\n",
    "        while True:\n",
    "        \n",
    "        # for idx in range(len(real_json['annotations'])):\n",
    "            i = real_json['annotations'][idx]\n",
    "            image_id = int(i['image_id'])\n",
    "            category_id = i['category_id']\n",
    "            img_path = real_json['images'][image_id]['file_name']\n",
    "            area = i['area']\n",
    "        \n",
    "            if category_id in pass_category:\n",
    "                idx+=1\n",
    "                continue\n",
    "\n",
    "        \n",
    "            img = cv2.imread(os.path.join(dataset_base,img_path))\n",
    "            img_moved = np.zeros((512, 512,3), dtype=np.uint8)\n",
    "            mask_moved = np.zeros((512, 512), dtype=np.uint8)\n",
    "            mask_t = []\n",
    "        \n",
    "            #아래 이중 for문은 하나의 annotation가져오는것임\n",
    "            for j in range(len(i['segmentation'])):\n",
    "                for k in range(len(i['segmentation'][j])//2):\n",
    "                    x = i['segmentation'][j][2*k]\n",
    "                    y = i['segmentation'][j][2*k+1]\n",
    "                    mask_t.append((x,y)) #좌표 collect\n",
    "            #mask_t는 annotation 좌표 tuple로 저장한 list\n",
    "            #mask : 좌표에 class값넣은것.\n",
    "            mask = fill_mask(mask_t)\n",
    "            mask = turn_to_uint(mask) \n",
    "        \n",
    "            res, _ ,a,center = cv2.connectedComponentsWithStats(mask)\n",
    "            x,y,w,h,_ = a[1] #object bbox\n",
    "        \n",
    "            # object가 하나로 이어져 있지 않거나 크기가 너무 작으면 패스\n",
    "            if res>2 or area <25000 or area>1700000:\n",
    "                idx+=1\n",
    "                continue\n",
    "\n",
    "            a = cv2.copyTo(img,mask) # RGB로 물체부분 추출하기\n",
    "    \n",
    "            #####boundary 넘어가는지 체크 근데 한바퀴만 돌 수 있게함\n",
    "            l = idx%6\n",
    "            new_x = adding_point[l][0]\n",
    "            new_y = adding_point[l][1]\n",
    "            cnt=0\n",
    "            while new_x+h >= 512 or new_y+w>=512:\n",
    "                cnt+=1\n",
    "                l=(l+1)%6\n",
    "                new_x = adding_point[l][0]\n",
    "                new_y = adding_point[l][1]\n",
    "                if cnt==5:\n",
    "                    break\n",
    "            if cnt==5:\n",
    "                idx+=1\n",
    "                continue\n",
    "                \n",
    "            # im_cnt+=1\n",
    "            ##### a = (512,512,3) mask = (512,512)\n",
    "            mask_moved[new_x:new_x+h, new_y:new_y+w] = mask[y:y+h,x:x+w]\n",
    "            img_moved[new_x:new_x+h, new_y:new_y+w] = a[y:y+h,x:x+w]\n",
    "            bg_img = cv2.copyTo(img_moved,mask_moved,bg_img) \n",
    "        \n",
    "            # annotations추가하는부분\n",
    "            ann = make_ann(ann,mask_moved,category_id)\n",
    "    \n",
    "            idx+=1\n",
    "            print(ann.shape)\n",
    "            cv2.imwrite(f\"synthesis/images/{im_id}.jpg\",bg_img)\n",
    "            cv2.imwrite(f\"synthesis/annotations/{im_id}.png\",ann)\n",
    "            im_id+=1\n",
    "\n",
    "            if im_id%10==0:\n",
    "                print(im_id)\n",
    "            break\n",
    "            # if im_cnt%2==0:  #im_cnt는 한 이미지에 몇개 합성할지 고르는것\n",
    "            #     cv2.imwrite(f\"synthesis/images/{im_id}.jpg\",bg_img)\n",
    "            #     cv2.imwrite(f\"synthesis/annotations/{im_id}.png\",ann)\n",
    "            #     im_id+=1\n",
    "            #     break\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8ee2ad-3364-47f1-a696-b019851bc8db",
   "metadata": {},
   "source": [
    "# annotation 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fe2712-41cc-4a42-bc98-f6d164b00c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_ann(a,mask,category_id):\n",
    "#     for j in range(512):\n",
    "#         for k in range(512):\n",
    "#             if mask[j][k]==255:\n",
    "#                 a[j][k] = category_id*15\n",
    "#             elif mask[j][k]<12 and mask[j][k]>0: #단순히 visualization 위해 넣음\n",
    "#                 a[j][k] =mask[j][k]*15\n",
    "#     return a\n",
    "\n",
    "# # 시각화하고싶은 annotaiton.png 입력)\n",
    "# mask = cv2.imread('/opt/ml/segmentation/moon/dataset/annotations/train/0000.png') \n",
    "# print(mask.shape)\n",
    "# mask_new = np.zeros((512, 512), dtype=np.uint8)\n",
    "# mask_new = mask[:,:,0]\n",
    "# a = np.zeros((512, 512,3), dtype=np.uint8)\n",
    "# res = make_ann(a,mask_new,8)\n",
    "# #test로 저장\n",
    "# cv2.imwrite(f\"test.png\",res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51654443-a065-4adc-8a32-eaaaa2f7215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_li = os.listdir('/opt/ml/segmentation/moon/dataset/annotations/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "546c96d4-2395-4d1f-b580-00e50e7fd10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0252.png\n"
     ]
    }
   ],
   "source": [
    "print(file_li[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d984ac17-a303-4905-a481-8f00757c36cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'.ipynb_checkpoints' in file_li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "155d69d4-a9ad-4502-8974-f15a2ed77a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in file_li:\n",
    "    path = os.path.join('/opt/ml/segmentation/moon/dataset/annotations/val',i)\n",
    "    a = cv2.imread(path)\n",
    "    a = a[:,:,0]\n",
    "    cv2.imwrite(path,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d19ba25-3db5-4917-ad10-a1be77529270",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
