2021-10-25 02:37:25,090 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.7.11 (default, Jul 27 2021, 14:32:16) [GCC 7.5.0]
CUDA available: True
GPU 0: Tesla V100-PCIE-32GB
CUDA_HOME: None
GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
PyTorch: 1.6.0
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.3-Product Build 20210617 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

TorchVision: 0.7.0
OpenCV: 4.5.3
MMCV: 1.3.15
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 10.1
MMSegmentation: 0.18.0+54bd4bd
------------------------------------------------------------

2021-10-25 02:37:25,090 - mmseg - INFO - Distributed training: False
2021-10-25 02:37:27,501 - mmseg - INFO - Config:
augs_num = 5
augs_epoch = 20
augs = [
    dict(type='CLAHE', p=1.0),
    dict(type='RandomGamma', p=1.0),
    dict(type='HueSaturationValue', p=1.0),
    dict(type='ChannelDropout', p=1.0),
    dict(type='ChannelShuffle', p=1.0),
    dict(type='RGBShift', p=1.0),
    dict(type='ShiftScaleRotate', p=1.0),
    dict(type='RandomRotate90', p=1.0),
    dict(type='PiecewiseAffine', p=1.0),
    dict(type='CoarseDropout', max_height=8, max_width=8, p=1.0),
    dict(type='ElasticTransform', border_mode=0, p=1.0),
    dict(type='ElasticTransform', p=1.0),
    dict(type='GridDistortion', border_mode=0, p=1.0),
    dict(type='RandomCrop', height=300, width=300, p=1.0),
    dict(type='OpticalDistortion', distort_limit=0.5, p=1.0)
]
alb_transform = [
    dict(type='VerticalFlip', p=0.3),
    dict(type='HorizontalFlip', p=0.3),
    dict(
        type='OneOf',
        transforms=[
            dict(type='GaussNoise', p=1.0),
            dict(type='GaussianBlur', p=1.0),
            dict(type='Blur', p=1.0)
        ],
        p=0.3),
    dict(type='OneOf', transforms=[dict(type='RGBShift', p=1.0)], p=0.3)
]
dataset_type = 'CustomDataset'
data_root = '/opt/ml/segmentation/input/mmseg/'
classes = [
    'Background', 'General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',
    'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'
]
palette = [[0, 0, 0], [192, 0, 128], [0, 128, 192], [0, 128, 64], [128, 0, 0],
           [64, 0, 128], [64, 0, 192], [192, 128, 64], [192, 192, 128],
           [64, 64, 128], [128, 0, 192]]
img_norm_cfg = dict(
    mean=[117.551, 112.259, 106.825],
    std=[59.866, 58.944, 62.162],
    to_rgb=True)
crop_size = (512, 512)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(type='Resize', img_scale=(512, 512)),
    dict(
        type='Albu',
        transforms=[
            dict(type='VerticalFlip', p=0.3),
            dict(type='HorizontalFlip', p=0.3),
            dict(
                type='OneOf',
                transforms=[
                    dict(type='GaussNoise', p=1.0),
                    dict(type='GaussianBlur', p=1.0),
                    dict(type='Blur', p=1.0)
                ],
                p=0.3),
            dict(
                type='OneOf', transforms=[dict(type='RGBShift', p=1.0)], p=0.3)
        ]),
    dict(type='RandomFlip', prob=0.3),
    dict(
        type='Normalize',
        mean=[117.551, 112.259, 106.825],
        std=[59.866, 58.944, 62.162],
        to_rgb=True),
    dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
val_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(512, 512),
        flip=False,
        transforms=[
            dict(type='Resize', img_scale=(512, 512), keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[117.551, 112.259, 106.825],
                std=[59.866, 58.944, 62.162],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img', 'gt_semantic_seg'])
        ])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(512, 512),
        flip=False,
        transforms=[
            dict(type='Resize', img_scale=(512, 512), keep_ratio=True),
            dict(
                type='Normalize',
                mean=[117.551, 112.259, 106.825],
                std=[59.866, 58.944, 62.162],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=16,
    workers_per_gpu=8,
    train=dict(
        classes=[
            'Background', 'General trash', 'Paper', 'Paper pack', 'Metal',
            'Glass', 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery',
            'Clothing'
        ],
        palette=[[0, 0, 0], [192, 0, 128], [0, 128, 192], [0, 128, 64],
                 [128, 0, 0], [64, 0, 128], [64, 0, 192], [192, 128, 64],
                 [192, 192, 128], [64, 64, 128], [128, 0, 192]],
        type='CustomDataset',
        reduce_zero_label=False,
        img_dir='/opt/ml/segmentation/input/mmseg/images/training',
        ann_dir='/opt/ml/segmentation/input/mmseg/annotations/training',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(type='Resize', img_scale=(512, 512)),
            dict(
                type='Albu',
                transforms=[
                    dict(type='VerticalFlip', p=0.3),
                    dict(type='HorizontalFlip', p=0.3),
                    dict(
                        type='OneOf',
                        transforms=[
                            dict(type='GaussNoise', p=1.0),
                            dict(type='GaussianBlur', p=1.0),
                            dict(type='Blur', p=1.0)
                        ],
                        p=0.3),
                    dict(
                        type='OneOf',
                        transforms=[dict(type='RGBShift', p=1.0)],
                        p=0.3)
                ]),
            dict(type='RandomFlip', prob=0.3),
            dict(
                type='Normalize',
                mean=[117.551, 112.259, 106.825],
                std=[59.866, 58.944, 62.162],
                to_rgb=True),
            dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_semantic_seg'])
        ]),
    val=dict(
        classes=[
            'Background', 'General trash', 'Paper', 'Paper pack', 'Metal',
            'Glass', 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery',
            'Clothing'
        ],
        palette=[[0, 0, 0], [192, 0, 128], [0, 128, 192], [0, 128, 64],
                 [128, 0, 0], [64, 0, 128], [64, 0, 192], [192, 128, 64],
                 [192, 192, 128], [64, 64, 128], [128, 0, 192]],
        type='CustomDataset',
        reduce_zero_label=False,
        img_dir='/opt/ml/segmentation/input/mmseg/images/validation',
        ann_dir='/opt/ml/segmentation/input/mmseg/annotations/validation',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(512, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', img_scale=(512, 512), keep_ratio=True),
                    dict(
                        type='Normalize',
                        mean=[117.551, 112.259, 106.825],
                        std=[59.866, 58.944, 62.162],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        classes=[
            'Background', 'General trash', 'Paper', 'Paper pack', 'Metal',
            'Glass', 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery',
            'Clothing'
        ],
        palette=[[0, 0, 0], [192, 0, 128], [0, 128, 192], [0, 128, 64],
                 [128, 0, 0], [64, 0, 128], [64, 0, 192], [192, 128, 64],
                 [192, 192, 128], [64, 64, 128], [128, 0, 192]],
        type='CustomDataset',
        reduce_zero_label=False,
        img_dir='/opt/ml/segmentation/input/mmseg/test',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(512, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', img_scale=(512, 512), keep_ratio=True),
                    dict(
                        type='Normalize',
                        mean=[117.551, 112.259, 106.825],
                        std=[59.866, 58.944, 62.162],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
lr = 0.0001
optimizer = dict(type='AdamW', lr=0.0001, weight_decay=0.01)
optimizer_config = dict(grad_clip=dict(max_norm=10, norm_type=2))
lr_config = dict(
    policy='CosineAnnealing',
    warmup='linear',
    warmup_iters=300,
    warmup_ratio=0.1,
    min_lr_ratio=7e-06)
total_epochs = 20
expr_name = 'CSWin_5_pret'
dist_params = dict(backend='nccl')
runner = dict(type='EpochBasedRunner', max_epochs=20)
checkpoint_config = dict(interval=20)
log_config = dict(
    interval=10,
    hooks=[
        dict(type='TextLoggerHook'),
        dict(
            type='WandbLoggerHook',
            init_kwargs=dict(
                project='segm_augs', name='CSWin_5_pret', entity='ark10806'))
    ])
custom_hooks = [dict(type='NumClassCheckHook')]
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
evaluation = dict(metric='mIoU', pre_eval=True, save_best='mIoU')
work_dir = './work_dirs/CSWin_5_pret'
gpu_ids = range(0, 1)
emb = 64
norm_cfg = dict(type='SyncBN', requires_grad=True)
model = dict(
    type='EncoderDecoder',
    pretrained=
    '/opt/ml/segmentation/mmsegmentation/configs/_base_/models/CSwin/pretrained/Converted_cswin_tiny_224.pth',
    backbone=dict(
        type='CSWin',
        embed_dim=64,
        patch_size=4,
        depth=[1, 2, 21, 1],
        num_heads=[2, 4, 8, 16],
        split_size=[1, 2, 7, 7],
        mlp_ratio=4.0,
        qkv_bias=True,
        qk_scale=None,
        drop_rate=0.0,
        attn_drop_rate=0.0,
        drop_path_rate=0.1),
    decode_head=dict(
        type='UPerHead',
        in_channels=[64, 128, 256, 512],
        in_index=[0, 1, 2, 3],
        pool_scales=(1, 2, 3, 6),
        channels=512,
        dropout_ratio=0.1,
        num_classes=11,
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        align_corners=False,
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
    auxiliary_head=dict(
        type='FCNHead',
        in_channels=256,
        in_index=2,
        channels=256,
        num_convs=1,
        concat_input=False,
        dropout_ratio=0.1,
        num_classes=11,
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        align_corners=False,
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=0.4)),
    train_cfg=dict(),
    test_cfg=dict(mode='whole'))

2021-10-25 02:37:27,501 - mmseg - INFO - Set random seed to 2021, deterministic: False
2021-10-25 02:37:28,044 - mmseg - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: norm.weight, norm.bias, head.weight, head.bias

missing keys in source state_dict: norm1.weight, norm1.bias, norm2.weight, norm2.bias, norm3.weight, norm3.bias, norm4.weight, norm4.bias

2021-10-25 02:37:28,831 - mmseg - INFO - initialize UPerHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
2021-10-25 02:37:29,077 - mmseg - INFO - initialize FCNHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
Name of parameter - Initialization information

backbone.stage1_conv_embed.0.weight - torch.Size([64, 3, 7, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1_conv_embed.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1_conv_embed.2.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage1_conv_embed.2.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.norm1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.qkv.weight - torch.Size([192, 64]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage1.0.qkv.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage1.0.norm1.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage1.0.norm1.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage1.0.proj.weight - torch.Size([64, 64]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage1.0.proj.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage1.0.attns.0.get_v.weight - torch.Size([32, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.attns.0.get_v.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.attns.1.get_v.weight - torch.Size([32, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.attns.1.get_v.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.mlp.fc1.weight - torch.Size([256, 64]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage1.0.mlp.fc1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage1.0.mlp.fc2.weight - torch.Size([64, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage1.0.mlp.fc2.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage1.0.norm2.weight - torch.Size([64]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage1.0.norm2.bias - torch.Size([64]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.merge1.conv.weight - torch.Size([128, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.merge1.conv.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.merge1.norm.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.merge1.norm.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.norm2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.qkv.weight - torch.Size([384, 128]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage2.0.qkv.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage2.0.norm1.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage2.0.norm1.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage2.0.proj.weight - torch.Size([128, 128]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage2.0.proj.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage2.0.attns.0.get_v.weight - torch.Size([64, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.attns.0.get_v.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.attns.1.get_v.weight - torch.Size([64, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.attns.1.get_v.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.mlp.fc1.weight - torch.Size([512, 128]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage2.0.mlp.fc1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage2.0.mlp.fc2.weight - torch.Size([128, 512]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage2.0.mlp.fc2.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage2.0.norm2.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage2.0.norm2.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage2.1.qkv.weight - torch.Size([384, 128]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage2.1.qkv.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage2.1.norm1.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage2.1.norm1.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage2.1.proj.weight - torch.Size([128, 128]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage2.1.proj.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage2.1.attns.0.get_v.weight - torch.Size([64, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.attns.0.get_v.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.attns.1.get_v.weight - torch.Size([64, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.attns.1.get_v.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.mlp.fc1.weight - torch.Size([512, 128]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage2.1.mlp.fc1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage2.1.mlp.fc2.weight - torch.Size([128, 512]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage2.1.mlp.fc2.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage2.1.norm2.weight - torch.Size([128]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage2.1.norm2.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.merge2.conv.weight - torch.Size([256, 128, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.merge2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.merge2.norm.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.merge2.norm.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.norm3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.0.qkv.weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.0.qkv.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.0.norm1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.0.norm1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.0.proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.0.proj.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.0.attns.0.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.0.attns.0.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.0.attns.1.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.0.attns.1.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.0.mlp.fc1.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.0.mlp.fc1.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.0.mlp.fc2.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.0.mlp.fc2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.0.norm2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.0.norm2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.1.qkv.weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.1.qkv.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.1.norm1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.1.norm1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.1.proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.1.proj.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.1.attns.0.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.1.attns.0.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.1.attns.1.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.1.attns.1.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.1.mlp.fc1.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.1.mlp.fc1.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.1.mlp.fc2.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.1.mlp.fc2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.1.norm2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.1.norm2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.2.qkv.weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.2.qkv.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.2.norm1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.2.norm1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.2.proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.2.proj.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.2.attns.0.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.2.attns.0.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.2.attns.1.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.2.attns.1.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.2.mlp.fc1.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.2.mlp.fc1.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.2.mlp.fc2.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.2.mlp.fc2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.2.norm2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.2.norm2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.3.qkv.weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.3.qkv.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.3.norm1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.3.norm1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.3.proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.3.proj.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.3.attns.0.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.3.attns.0.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.3.attns.1.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.3.attns.1.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.3.mlp.fc1.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.3.mlp.fc1.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.3.mlp.fc2.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.3.mlp.fc2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.3.norm2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.3.norm2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.4.qkv.weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.4.qkv.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.4.norm1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.4.norm1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.4.proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.4.proj.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.4.attns.0.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.4.attns.0.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.4.attns.1.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.4.attns.1.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.4.mlp.fc1.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.4.mlp.fc1.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.4.mlp.fc2.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.4.mlp.fc2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.4.norm2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.4.norm2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.5.qkv.weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.5.qkv.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.5.norm1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.5.norm1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.5.proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.5.proj.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.5.attns.0.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.5.attns.0.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.5.attns.1.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.5.attns.1.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.5.mlp.fc1.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.5.mlp.fc1.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.5.mlp.fc2.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.5.mlp.fc2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.5.norm2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.5.norm2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.6.qkv.weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.6.qkv.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.6.norm1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.6.norm1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.6.proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.6.proj.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.6.attns.0.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.6.attns.0.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.6.attns.1.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.6.attns.1.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.6.mlp.fc1.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.6.mlp.fc1.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.6.mlp.fc2.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.6.mlp.fc2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.6.norm2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.6.norm2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.7.qkv.weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.7.qkv.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.7.norm1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.7.norm1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.7.proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.7.proj.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.7.attns.0.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.7.attns.0.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.7.attns.1.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.7.attns.1.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.7.mlp.fc1.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.7.mlp.fc1.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.7.mlp.fc2.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.7.mlp.fc2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.7.norm2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.7.norm2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.8.qkv.weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.8.qkv.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.8.norm1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.8.norm1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.8.proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.8.proj.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.8.attns.0.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.8.attns.0.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.8.attns.1.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.8.attns.1.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.8.mlp.fc1.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.8.mlp.fc1.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.8.mlp.fc2.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.8.mlp.fc2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.8.norm2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.8.norm2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.9.qkv.weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.9.qkv.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.9.norm1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.9.norm1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.9.proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.9.proj.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.9.attns.0.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.9.attns.0.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.9.attns.1.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.9.attns.1.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.9.mlp.fc1.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.9.mlp.fc1.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.9.mlp.fc2.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.9.mlp.fc2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.9.norm2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.9.norm2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.10.qkv.weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.10.qkv.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.10.norm1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.10.norm1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.10.proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.10.proj.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.10.attns.0.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.10.attns.0.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.10.attns.1.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.10.attns.1.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.10.mlp.fc1.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.10.mlp.fc1.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.10.mlp.fc2.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.10.mlp.fc2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.10.norm2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.10.norm2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.11.qkv.weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.11.qkv.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.11.norm1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.11.norm1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.11.proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.11.proj.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.11.attns.0.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.11.attns.0.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.11.attns.1.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.11.attns.1.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.11.mlp.fc1.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.11.mlp.fc1.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.11.mlp.fc2.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.11.mlp.fc2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.11.norm2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.11.norm2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.12.qkv.weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.12.qkv.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.12.norm1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.12.norm1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.12.proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.12.proj.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.12.attns.0.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.12.attns.0.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.12.attns.1.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.12.attns.1.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.12.mlp.fc1.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.12.mlp.fc1.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.12.mlp.fc2.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.12.mlp.fc2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.12.norm2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.12.norm2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.13.qkv.weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.13.qkv.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.13.norm1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.13.norm1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.13.proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.13.proj.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.13.attns.0.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.13.attns.0.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.13.attns.1.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.13.attns.1.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.13.mlp.fc1.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.13.mlp.fc1.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.13.mlp.fc2.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.13.mlp.fc2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.13.norm2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.13.norm2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.14.qkv.weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.14.qkv.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.14.norm1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.14.norm1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.14.proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.14.proj.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.14.attns.0.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.14.attns.0.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.14.attns.1.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.14.attns.1.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.14.mlp.fc1.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.14.mlp.fc1.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.14.mlp.fc2.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.14.mlp.fc2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.14.norm2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.14.norm2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.15.qkv.weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.15.qkv.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.15.norm1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.15.norm1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.15.proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.15.proj.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.15.attns.0.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.15.attns.0.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.15.attns.1.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.15.attns.1.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.15.mlp.fc1.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.15.mlp.fc1.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.15.mlp.fc2.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.15.mlp.fc2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.15.norm2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.15.norm2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.16.qkv.weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.16.qkv.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.16.norm1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.16.norm1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.16.proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.16.proj.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.16.attns.0.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.16.attns.0.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.16.attns.1.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.16.attns.1.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.16.mlp.fc1.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.16.mlp.fc1.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.16.mlp.fc2.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.16.mlp.fc2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.16.norm2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.16.norm2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.17.qkv.weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.17.qkv.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.17.norm1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.17.norm1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.17.proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.17.proj.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.17.attns.0.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.17.attns.0.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.17.attns.1.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.17.attns.1.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.17.mlp.fc1.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.17.mlp.fc1.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.17.mlp.fc2.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.17.mlp.fc2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.17.norm2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.17.norm2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.18.qkv.weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.18.qkv.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.18.norm1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.18.norm1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.18.proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.18.proj.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.18.attns.0.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.18.attns.0.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.18.attns.1.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.18.attns.1.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.18.mlp.fc1.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.18.mlp.fc1.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.18.mlp.fc2.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.18.mlp.fc2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.18.norm2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.18.norm2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.19.qkv.weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.19.qkv.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.19.norm1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.19.norm1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.19.proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.19.proj.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.19.attns.0.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.19.attns.0.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.19.attns.1.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.19.attns.1.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.19.mlp.fc1.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.19.mlp.fc1.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.19.mlp.fc2.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.19.mlp.fc2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.19.norm2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.19.norm2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.20.qkv.weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.20.qkv.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.20.norm1.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.20.norm1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.20.proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.20.proj.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.20.attns.0.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.20.attns.0.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.20.attns.1.get_v.weight - torch.Size([128, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.20.attns.1.get_v.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage3.20.mlp.fc1.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.20.mlp.fc1.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.20.mlp.fc2.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.20.mlp.fc2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.20.norm2.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage3.20.norm2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.merge3.conv.weight - torch.Size([512, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.merge3.conv.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.merge3.norm.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.merge3.norm.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage4.0.qkv.weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage4.0.qkv.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage4.0.norm1.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage4.0.norm1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage4.0.proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage4.0.proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage4.0.attns.0.get_v.weight - torch.Size([512, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage4.0.attns.0.get_v.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage4.0.mlp.fc1.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage4.0.mlp.fc1.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage4.0.mlp.fc2.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage4.0.mlp.fc2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage4.0.norm2.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.stage4.0.norm2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in CSWin  

backbone.norm4.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm4.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.conv_seg.weight - torch.Size([11, 512, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.conv_seg.bias - torch.Size([11]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.psp_modules.0.1.conv.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.0.1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.0.1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.1.1.conv.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.1.1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.1.1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.2.1.conv.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.2.1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.2.1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.3.1.conv.weight - torch.Size([512, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.3.1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.3.1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.bottleneck.conv.weight - torch.Size([512, 2560, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

decode_head.bottleneck.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.bottleneck.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.lateral_convs.0.conv.weight - torch.Size([512, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.lateral_convs.0.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.lateral_convs.0.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.lateral_convs.1.conv.weight - torch.Size([512, 128, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.lateral_convs.1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.lateral_convs.1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.lateral_convs.2.conv.weight - torch.Size([512, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.lateral_convs.2.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.lateral_convs.2.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_convs.0.conv.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_convs.0.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_convs.0.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_convs.1.conv.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_convs.1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_convs.1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_convs.2.conv.weight - torch.Size([512, 512, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_convs.2.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_convs.2.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_bottleneck.conv.weight - torch.Size([512, 2048, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

decode_head.fpn_bottleneck.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.fpn_bottleneck.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.conv_seg.weight - torch.Size([11, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

auxiliary_head.conv_seg.bias - torch.Size([11]): 
NormalInit: mean=0, std=0.01, bias=0 

auxiliary_head.convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  
2021-10-25 02:37:29,088 - mmseg - INFO - EncoderDecoder(
  (backbone): CSWin(
    (stage1_conv_embed): Sequential(
      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(2, 2))
      (1): Rearrange('b c h w -> b (h w) c', h=56, w=56)
      (2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (stage1): ModuleList(
      (0): CSWinBlock(
        (qkv): Linear(in_features=64, out_features=192, bias=True)
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (proj): Linear(in_features=64, out_features=64, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
        (attns): ModuleList(
          (0): LePEAttention(
            (get_v): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
          (1): LePEAttention(
            (get_v): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
        )
        (drop_path): Identity()
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=256, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=256, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
    )
    (merge1): Merge_Block(
      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    (stage2): ModuleList(
      (0): CSWinBlock(
        (qkv): Linear(in_features=128, out_features=384, bias=True)
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (proj): Linear(in_features=128, out_features=128, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
        (attns): ModuleList(
          (0): LePEAttention(
            (get_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
          (1): LePEAttention(
            (get_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
        )
        (drop_path): DropPath()
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=512, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (1): CSWinBlock(
        (qkv): Linear(in_features=128, out_features=384, bias=True)
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (proj): Linear(in_features=128, out_features=128, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
        (attns): ModuleList(
          (0): LePEAttention(
            (get_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
          (1): LePEAttention(
            (get_v): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
        )
        (drop_path): DropPath()
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=512, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
    (merge2): Merge_Block(
      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (stage3): ModuleList(
      (0): CSWinBlock(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
        (attns): ModuleList(
          (0): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
          (1): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
        )
        (drop_path): DropPath()
        (mlp): Mlp(
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (1): CSWinBlock(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
        (attns): ModuleList(
          (0): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
          (1): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
        )
        (drop_path): DropPath()
        (mlp): Mlp(
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (2): CSWinBlock(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
        (attns): ModuleList(
          (0): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
          (1): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
        )
        (drop_path): DropPath()
        (mlp): Mlp(
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (3): CSWinBlock(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
        (attns): ModuleList(
          (0): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
          (1): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
        )
        (drop_path): DropPath()
        (mlp): Mlp(
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (4): CSWinBlock(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
        (attns): ModuleList(
          (0): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
          (1): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
        )
        (drop_path): DropPath()
        (mlp): Mlp(
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (5): CSWinBlock(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
        (attns): ModuleList(
          (0): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
          (1): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
        )
        (drop_path): DropPath()
        (mlp): Mlp(
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (6): CSWinBlock(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
        (attns): ModuleList(
          (0): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
          (1): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
        )
        (drop_path): DropPath()
        (mlp): Mlp(
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (7): CSWinBlock(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
        (attns): ModuleList(
          (0): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
          (1): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
        )
        (drop_path): DropPath()
        (mlp): Mlp(
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (8): CSWinBlock(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
        (attns): ModuleList(
          (0): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
          (1): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
        )
        (drop_path): DropPath()
        (mlp): Mlp(
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (9): CSWinBlock(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
        (attns): ModuleList(
          (0): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
          (1): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
        )
        (drop_path): DropPath()
        (mlp): Mlp(
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (10): CSWinBlock(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
        (attns): ModuleList(
          (0): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
          (1): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
        )
        (drop_path): DropPath()
        (mlp): Mlp(
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (11): CSWinBlock(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
        (attns): ModuleList(
          (0): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
          (1): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
        )
        (drop_path): DropPath()
        (mlp): Mlp(
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (12): CSWinBlock(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
        (attns): ModuleList(
          (0): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
          (1): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
        )
        (drop_path): DropPath()
        (mlp): Mlp(
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (13): CSWinBlock(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
        (attns): ModuleList(
          (0): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
          (1): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
        )
        (drop_path): DropPath()
        (mlp): Mlp(
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (14): CSWinBlock(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
        (attns): ModuleList(
          (0): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
          (1): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
        )
        (drop_path): DropPath()
        (mlp): Mlp(
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (15): CSWinBlock(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
        (attns): ModuleList(
          (0): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
          (1): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
        )
        (drop_path): DropPath()
        (mlp): Mlp(
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (16): CSWinBlock(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
        (attns): ModuleList(
          (0): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
          (1): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
        )
        (drop_path): DropPath()
        (mlp): Mlp(
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (17): CSWinBlock(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
        (attns): ModuleList(
          (0): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
          (1): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
        )
        (drop_path): DropPath()
        (mlp): Mlp(
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (18): CSWinBlock(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
        (attns): ModuleList(
          (0): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
          (1): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
        )
        (drop_path): DropPath()
        (mlp): Mlp(
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (19): CSWinBlock(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
        (attns): ModuleList(
          (0): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
          (1): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
        )
        (drop_path): DropPath()
        (mlp): Mlp(
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (20): CSWinBlock(
        (qkv): Linear(in_features=256, out_features=768, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (proj): Linear(in_features=256, out_features=256, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
        (attns): ModuleList(
          (0): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
          (1): LePEAttention(
            (get_v): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
        )
        (drop_path): DropPath()
        (mlp): Mlp(
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
    (merge3): Merge_Block(
      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (stage4): ModuleList(
      (0): CSWinBlock(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
        (attns): ModuleList(
          (0): LePEAttention(
            (get_v): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            (attn_drop): Dropout(p=0.0, inplace=False)
          )
        )
        (drop_path): DropPath()
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (norm4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    input_transform=multiple_select, ignore_index=255, align_corners=False
    (loss_decode): ModuleList(
      (0): CrossEntropyLoss()
    )
    (conv_seg): Conv2d(512, 11, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (0): Sequential(
        (0): AdaptiveAvgPool2d(output_size=1)
        (1): ConvModule(
          (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (1): Sequential(
        (0): AdaptiveAvgPool2d(output_size=2)
        (1): ConvModule(
          (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (2): Sequential(
        (0): AdaptiveAvgPool2d(output_size=3)
        (1): ConvModule(
          (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (3): Sequential(
        (0): AdaptiveAvgPool2d(output_size=6)
        (1): ConvModule(
          (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(2560, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
      (1): ConvModule(
        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
      (2): ConvModule(
        (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
      (1): ConvModule(
        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
      (2): ConvModule(
        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU()
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
  (auxiliary_head): FCNHead(
    input_transform=None, ignore_index=255, align_corners=False
    (loss_decode): ModuleList(
      (0): CrossEntropyLoss()
    )
    (conv_seg): Conv2d(256, 11, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (convs): Sequential(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
)
2021-10-25 02:37:29,137 - mmseg - INFO - Loaded 2617 images
2021-10-25 02:37:35,337 - mmseg - INFO - Loaded 655 images
2021-10-25 02:37:35,337 - mmseg - INFO - Start running, host: root@1f2dea58e1a6, work_dir: /opt/ml/segmentation/mmsegmentation/configs/_base_/models/CSwin/work_dirs/CSWin_5_pret
2021-10-25 02:37:35,338 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
before_train_iter:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
after_run:
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
2021-10-25 02:37:35,338 - mmseg - INFO - workflow: [('train', 1)], max: 20 epochs
2021-10-25 02:38:14,350 - mmseg - INFO - Epoch [1][10/163]	lr: 1.270e-05, eta: 2:20:04, time: 2.586, data_time: 0.284, memory: 29235, decode.loss_ce: 2.4410, decode.acc_seg: 13.0011, aux.loss_ce: 0.9660, aux.acc_seg: 6.0324, loss: 3.4070, grad_norm: 6.3902
2021-10-25 02:38:37,073 - mmseg - INFO - Epoch [1][20/163]	lr: 1.570e-05, eta: 2:11:10, time: 2.272, data_time: 0.010, memory: 29235, decode.loss_ce: 2.3317, decode.acc_seg: 35.4218, aux.loss_ce: 0.9507, aux.acc_seg: 14.5246, loss: 3.2824, grad_norm: 6.1257
2021-10-25 02:38:59,758 - mmseg - INFO - Epoch [1][30/163]	lr: 1.870e-05, eta: 2:07:52, time: 2.268, data_time: 0.010, memory: 29235, decode.loss_ce: 2.1557, decode.acc_seg: 51.7975, aux.loss_ce: 0.9299, aux.acc_seg: 33.6488, loss: 3.0856, grad_norm: 5.7198
2021-10-25 02:39:22,370 - mmseg - INFO - Epoch [1][40/163]	lr: 2.170e-05, eta: 2:05:57, time: 2.261, data_time: 0.010, memory: 29235, decode.loss_ce: 2.0559, decode.acc_seg: 57.0744, aux.loss_ce: 0.9086, aux.acc_seg: 47.9188, loss: 2.9645, grad_norm: 5.7914
2021-10-25 02:39:44,980 - mmseg - INFO - Epoch [1][50/163]	lr: 2.470e-05, eta: 2:04:38, time: 2.261, data_time: 0.010, memory: 29235, decode.loss_ce: 1.8955, decode.acc_seg: 62.8569, aux.loss_ce: 0.8825, aux.acc_seg: 55.6412, loss: 2.7780, grad_norm: 5.2831
2021-10-25 02:40:07,595 - mmseg - INFO - Epoch [1][60/163]	lr: 2.770e-05, eta: 2:03:38, time: 2.261, data_time: 0.010, memory: 29235, decode.loss_ce: 1.7782, decode.acc_seg: 68.5948, aux.loss_ce: 0.8499, aux.acc_seg: 61.6687, loss: 2.6281, grad_norm: 5.0501
2021-10-25 02:40:30,158 - mmseg - INFO - Epoch [1][70/163]	lr: 3.070e-05, eta: 2:02:47, time: 2.256, data_time: 0.010, memory: 29235, decode.loss_ce: 1.6957, decode.acc_seg: 66.9115, aux.loss_ce: 0.8169, aux.acc_seg: 62.4446, loss: 2.5127, grad_norm: 4.7102
2021-10-25 02:40:52,740 - mmseg - INFO - Epoch [1][80/163]	lr: 3.370e-05, eta: 2:02:03, time: 2.258, data_time: 0.011, memory: 29235, decode.loss_ce: 1.6029, decode.acc_seg: 70.9065, aux.loss_ce: 0.7880, aux.acc_seg: 65.7129, loss: 2.3908, grad_norm: 4.7790
2021-10-25 02:41:15,310 - mmseg - INFO - Epoch [1][90/163]	lr: 3.670e-05, eta: 2:01:24, time: 2.257, data_time: 0.010, memory: 29235, decode.loss_ce: 1.5959, decode.acc_seg: 67.7446, aux.loss_ce: 0.7759, aux.acc_seg: 63.1683, loss: 2.3718, grad_norm: 4.5540
2021-10-25 02:41:37,845 - mmseg - INFO - Epoch [1][100/163]	lr: 3.970e-05, eta: 2:00:47, time: 2.253, data_time: 0.010, memory: 29235, decode.loss_ce: 1.4961, decode.acc_seg: 71.1338, aux.loss_ce: 0.7508, aux.acc_seg: 65.8760, loss: 2.2468, grad_norm: 4.4653
2021-10-25 02:42:00,395 - mmseg - INFO - Epoch [1][110/163]	lr: 4.270e-05, eta: 2:00:13, time: 2.255, data_time: 0.011, memory: 29235, decode.loss_ce: 1.4367, decode.acc_seg: 70.1154, aux.loss_ce: 0.7282, aux.acc_seg: 65.8161, loss: 2.1649, grad_norm: 4.1795
2021-10-25 02:42:22,937 - mmseg - INFO - Epoch [1][120/163]	lr: 4.570e-05, eta: 1:59:41, time: 2.254, data_time: 0.012, memory: 29235, decode.loss_ce: 1.4122, decode.acc_seg: 67.9419, aux.loss_ce: 0.7146, aux.acc_seg: 63.5777, loss: 2.1268, grad_norm: 4.0631
2021-10-25 02:42:45,507 - mmseg - INFO - Epoch [1][130/163]	lr: 4.870e-05, eta: 1:59:11, time: 2.257, data_time: 0.013, memory: 29235, decode.loss_ce: 1.3497, decode.acc_seg: 70.8987, aux.loss_ce: 0.7024, aux.acc_seg: 65.9868, loss: 2.0520, grad_norm: 4.1466
2021-10-25 02:43:08,052 - mmseg - INFO - Epoch [1][140/163]	lr: 5.170e-05, eta: 1:58:41, time: 2.254, data_time: 0.011, memory: 29235, decode.loss_ce: 1.2323, decode.acc_seg: 73.2423, aux.loss_ce: 0.6582, aux.acc_seg: 66.4042, loss: 1.8905, grad_norm: 3.9412
2021-10-25 02:43:30,601 - mmseg - INFO - Epoch [1][150/163]	lr: 5.470e-05, eta: 1:58:13, time: 2.255, data_time: 0.012, memory: 29235, decode.loss_ce: 1.2108, decode.acc_seg: 73.0189, aux.loss_ce: 0.6508, aux.acc_seg: 66.0915, loss: 1.8616, grad_norm: 3.9230
2021-10-25 02:43:53,140 - mmseg - INFO - Epoch [1][160/163]	lr: 5.770e-05, eta: 1:57:45, time: 2.254, data_time: 0.011, memory: 29235, decode.loss_ce: 1.1645, decode.acc_seg: 72.7379, aux.loss_ce: 0.6326, aux.acc_seg: 66.2668, loss: 1.7971, grad_norm: 3.5461
2021-10-25 02:44:54,582 - mmseg - INFO - per class results:
2021-10-25 02:44:54,583 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|   Background  | 80.79 | 89.67 |
| General trash |  0.0  |  0.0  |
|     Paper     | 27.06 | 52.62 |
|   Paper pack  |  0.0  |  0.0  |
|     Metal     |  0.0  |  0.0  |
|     Glass     |  0.0  |  0.0  |
|    Plastic    |  0.14 |  0.14 |
|   Styrofoam   |  0.0  |  0.0  |
|  Plastic bag  | 31.77 | 57.51 |
|    Battery    |  0.0  |  0.0  |
|    Clothing   |  0.0  |  0.0  |
+---------------+-------+-------+
2021-10-25 02:44:54,583 - mmseg - INFO - Summary:
2021-10-25 02:44:54,583 - mmseg - INFO - 
+------+-------+-------+
| aAcc |  mIoU |  mAcc |
+------+-------+-------+
| 74.2 | 12.71 | 18.18 |
+------+-------+-------+
2021-10-25 02:44:56,076 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_epoch_1.pth.
2021-10-25 02:44:56,076 - mmseg - INFO - Best mIoU is 0.1271 at 1 epoch.
2021-10-25 02:44:56,080 - mmseg - INFO - Exp name: UperCSwinT.py
2021-10-25 02:44:56,080 - mmseg - INFO - Epoch(val) [1][655]	aAcc: 0.7420, mIoU: 0.1271, mAcc: 0.1818, IoU.Background: 0.8079, IoU.General trash: 0.0000, IoU.Paper: 0.2706, IoU.Paper pack: 0.0000, IoU.Metal: 0.0000, IoU.Glass: 0.0000, IoU.Plastic: 0.0014, IoU.Styrofoam: 0.0000, IoU.Plastic bag: 0.3177, IoU.Battery: 0.0000, IoU.Clothing: 0.0000, Acc.Background: 0.8967, Acc.General trash: 0.0000, Acc.Paper: 0.5262, Acc.Paper pack: 0.0000, Acc.Metal: 0.0000, Acc.Glass: 0.0000, Acc.Plastic: 0.0014, Acc.Styrofoam: 0.0000, Acc.Plastic bag: 0.5751, Acc.Battery: 0.0000, Acc.Clothing: 0.0000
2021-10-25 02:45:21,660 - mmseg - INFO - Epoch [2][10/163]	lr: 6.122e-05, eta: 1:56:02, time: 2.556, data_time: 0.303, memory: 29235, decode.loss_ce: 1.1495, decode.acc_seg: 72.3378, aux.loss_ce: 0.6130, aux.acc_seg: 64.6218, loss: 1.7625, grad_norm: 3.2343
2021-10-25 02:45:44,225 - mmseg - INFO - Epoch [2][20/163]	lr: 6.420e-05, eta: 1:55:40, time: 2.257, data_time: 0.011, memory: 29235, decode.loss_ce: 1.0194, decode.acc_seg: 75.3584, aux.loss_ce: 0.5721, aux.acc_seg: 68.2670, loss: 1.5915, grad_norm: 3.0864
2021-10-25 02:46:06,766 - mmseg - INFO - Epoch [2][30/163]	lr: 6.718e-05, eta: 1:55:17, time: 2.254, data_time: 0.010, memory: 29235, decode.loss_ce: 0.9770, decode.acc_seg: 76.9442, aux.loss_ce: 0.5529, aux.acc_seg: 69.6226, loss: 1.5299, grad_norm: 3.1226
2021-10-25 02:46:29,297 - mmseg - INFO - Epoch [2][40/163]	lr: 7.017e-05, eta: 1:54:54, time: 2.253, data_time: 0.010, memory: 29235, decode.loss_ce: 0.9769, decode.acc_seg: 75.2205, aux.loss_ce: 0.5401, aux.acc_seg: 68.3431, loss: 1.5170, grad_norm: 2.8604
2021-10-25 02:46:51,836 - mmseg - INFO - Epoch [2][50/163]	lr: 7.315e-05, eta: 1:54:32, time: 2.254, data_time: 0.011, memory: 29235, decode.loss_ce: 0.9208, decode.acc_seg: 76.2915, aux.loss_ce: 0.5129, aux.acc_seg: 70.7905, loss: 1.4336, grad_norm: 2.6773
2021-10-25 02:47:14,378 - mmseg - INFO - Epoch [2][60/163]	lr: 7.613e-05, eta: 1:54:09, time: 2.254, data_time: 0.011, memory: 29235, decode.loss_ce: 0.9452, decode.acc_seg: 74.8814, aux.loss_ce: 0.5077, aux.acc_seg: 68.9089, loss: 1.4530, grad_norm: 2.6416
2021-10-25 02:47:36,902 - mmseg - INFO - Epoch [2][70/163]	lr: 7.911e-05, eta: 1:53:46, time: 2.252, data_time: 0.010, memory: 29235, decode.loss_ce: 0.9652, decode.acc_seg: 74.6758, aux.loss_ce: 0.5020, aux.acc_seg: 70.3965, loss: 1.4671, grad_norm: 2.4754
2021-10-25 02:47:59,411 - mmseg - INFO - Epoch [2][80/163]	lr: 8.209e-05, eta: 1:53:23, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.8866, decode.acc_seg: 75.8635, aux.loss_ce: 0.4694, aux.acc_seg: 71.8935, loss: 1.3560, grad_norm: 2.5632
2021-10-25 02:48:21,925 - mmseg - INFO - Epoch [2][90/163]	lr: 8.507e-05, eta: 1:53:00, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.8436, decode.acc_seg: 76.6031, aux.loss_ce: 0.4514, aux.acc_seg: 71.8318, loss: 1.2949, grad_norm: 2.4615
2021-10-25 02:48:44,467 - mmseg - INFO - Epoch [2][100/163]	lr: 8.805e-05, eta: 1:52:37, time: 2.254, data_time: 0.011, memory: 29235, decode.loss_ce: 0.8979, decode.acc_seg: 74.9982, aux.loss_ce: 0.4552, aux.acc_seg: 71.2209, loss: 1.3531, grad_norm: 2.3653
2021-10-25 02:49:06,987 - mmseg - INFO - Epoch [2][110/163]	lr: 9.104e-05, eta: 1:52:14, time: 2.252, data_time: 0.010, memory: 29235, decode.loss_ce: 0.8256, decode.acc_seg: 77.1868, aux.loss_ce: 0.4285, aux.acc_seg: 73.8761, loss: 1.2540, grad_norm: 2.2249
2021-10-25 02:49:29,514 - mmseg - INFO - Epoch [2][120/163]	lr: 9.402e-05, eta: 1:51:52, time: 2.253, data_time: 0.010, memory: 29235, decode.loss_ce: 0.8111, decode.acc_seg: 76.7613, aux.loss_ce: 0.4153, aux.acc_seg: 73.0908, loss: 1.2264, grad_norm: 2.1905
2021-10-25 02:49:52,022 - mmseg - INFO - Epoch [2][130/163]	lr: 9.700e-05, eta: 1:51:29, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.8163, decode.acc_seg: 76.7865, aux.loss_ce: 0.4067, aux.acc_seg: 73.3506, loss: 1.2230, grad_norm: 1.9011
2021-10-25 02:50:14,543 - mmseg - INFO - Epoch [2][140/163]	lr: 9.938e-05, eta: 1:51:06, time: 2.252, data_time: 0.010, memory: 29235, decode.loss_ce: 0.8065, decode.acc_seg: 76.6670, aux.loss_ce: 0.3984, aux.acc_seg: 73.6309, loss: 1.2048, grad_norm: 2.0727
2021-10-25 02:50:37,052 - mmseg - INFO - Epoch [2][150/163]	lr: 9.938e-05, eta: 1:50:43, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.7838, decode.acc_seg: 77.4385, aux.loss_ce: 0.3788, aux.acc_seg: 74.8260, loss: 1.1626, grad_norm: 2.0409
2021-10-25 02:50:59,546 - mmseg - INFO - Epoch [2][160/163]	lr: 9.938e-05, eta: 1:50:20, time: 2.249, data_time: 0.010, memory: 29235, decode.loss_ce: 0.7470, decode.acc_seg: 78.2954, aux.loss_ce: 0.3632, aux.acc_seg: 76.8487, loss: 1.1102, grad_norm: 1.8789
2021-10-25 02:52:01,841 - mmseg - INFO - per class results:
2021-10-25 02:52:01,842 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|   Background  | 83.22 | 93.36 |
| General trash | 14.23 |  23.0 |
|     Paper     | 31.71 | 48.83 |
|   Paper pack  |  0.0  |  0.0  |
|     Metal     |  0.0  |  0.0  |
|     Glass     |  0.0  |  0.0  |
|    Plastic    |  0.1  |  0.1  |
|   Styrofoam   |  0.11 |  0.11 |
|  Plastic bag  | 34.39 | 58.49 |
|    Battery    |  0.0  |  0.0  |
|    Clothing   |  0.0  |  0.0  |
+---------------+-------+-------+
2021-10-25 02:52:01,842 - mmseg - INFO - Summary:
2021-10-25 02:52:01,843 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 77.04 | 14.89 | 20.35 |
+-------+-------+-------+
2021-10-25 02:52:03,521 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_epoch_2.pth.
2021-10-25 02:52:03,521 - mmseg - INFO - Best mIoU is 0.1489 at 2 epoch.
2021-10-25 02:52:03,525 - mmseg - INFO - Exp name: UperCSwinT.py
2021-10-25 02:52:03,526 - mmseg - INFO - Epoch(val) [2][655]	aAcc: 0.7704, mIoU: 0.1489, mAcc: 0.2035, IoU.Background: 0.8322, IoU.General trash: 0.1423, IoU.Paper: 0.3171, IoU.Paper pack: 0.0000, IoU.Metal: 0.0000, IoU.Glass: 0.0000, IoU.Plastic: 0.0010, IoU.Styrofoam: 0.0011, IoU.Plastic bag: 0.3439, IoU.Battery: 0.0000, IoU.Clothing: 0.0000, Acc.Background: 0.9336, Acc.General trash: 0.2300, Acc.Paper: 0.4883, Acc.Paper pack: 0.0000, Acc.Metal: 0.0000, Acc.Glass: 0.0000, Acc.Plastic: 0.0010, Acc.Styrofoam: 0.0011, Acc.Plastic bag: 0.5849, Acc.Battery: 0.0000, Acc.Clothing: 0.0000
2021-10-25 02:52:29,256 - mmseg - INFO - Epoch [3][10/163]	lr: 9.755e-05, eta: 1:49:19, time: 2.572, data_time: 0.319, memory: 29235, decode.loss_ce: 0.7738, decode.acc_seg: 76.1915, aux.loss_ce: 0.3727, aux.acc_seg: 74.1471, loss: 1.1466, grad_norm: 2.1344
2021-10-25 02:52:51,803 - mmseg - INFO - Epoch [3][20/163]	lr: 9.755e-05, eta: 1:48:58, time: 2.255, data_time: 0.010, memory: 29235, decode.loss_ce: 0.7207, decode.acc_seg: 77.8283, aux.loss_ce: 0.3533, aux.acc_seg: 75.4027, loss: 1.0741, grad_norm: 1.9101
2021-10-25 02:53:14,376 - mmseg - INFO - Epoch [3][30/163]	lr: 9.755e-05, eta: 1:48:37, time: 2.257, data_time: 0.010, memory: 29235, decode.loss_ce: 0.7086, decode.acc_seg: 79.6155, aux.loss_ce: 0.3419, aux.acc_seg: 77.4406, loss: 1.0505, grad_norm: 1.6597
2021-10-25 02:53:36,947 - mmseg - INFO - Epoch [3][40/163]	lr: 9.755e-05, eta: 1:48:15, time: 2.257, data_time: 0.010, memory: 29235, decode.loss_ce: 0.7673, decode.acc_seg: 76.4505, aux.loss_ce: 0.3537, aux.acc_seg: 74.7648, loss: 1.1209, grad_norm: 2.1020
2021-10-25 02:53:59,601 - mmseg - INFO - Epoch [3][50/163]	lr: 9.755e-05, eta: 1:47:54, time: 2.265, data_time: 0.011, memory: 29235, decode.loss_ce: 0.6911, decode.acc_seg: 79.1336, aux.loss_ce: 0.3373, aux.acc_seg: 76.0848, loss: 1.0285, grad_norm: 2.0290
2021-10-25 02:54:22,125 - mmseg - INFO - Epoch [3][60/163]	lr: 9.755e-05, eta: 1:47:32, time: 2.252, data_time: 0.010, memory: 29235, decode.loss_ce: 0.7435, decode.acc_seg: 77.3527, aux.loss_ce: 0.3471, aux.acc_seg: 75.0954, loss: 1.0906, grad_norm: 2.3083
2021-10-25 02:54:44,653 - mmseg - INFO - Epoch [3][70/163]	lr: 9.755e-05, eta: 1:47:11, time: 2.253, data_time: 0.010, memory: 29235, decode.loss_ce: 0.8080, decode.acc_seg: 75.3395, aux.loss_ce: 0.3659, aux.acc_seg: 74.3343, loss: 1.1739, grad_norm: 2.2222
2021-10-25 02:55:07,164 - mmseg - INFO - Epoch [3][80/163]	lr: 9.755e-05, eta: 1:46:48, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.8548, decode.acc_seg: 74.3337, aux.loss_ce: 0.3864, aux.acc_seg: 72.8347, loss: 1.2412, grad_norm: 1.8981
2021-10-25 02:55:29,679 - mmseg - INFO - Epoch [3][90/163]	lr: 9.755e-05, eta: 1:46:26, time: 2.252, data_time: 0.010, memory: 29235, decode.loss_ce: 0.6970, decode.acc_seg: 79.6167, aux.loss_ce: 0.3253, aux.acc_seg: 77.7641, loss: 1.0222, grad_norm: 2.2247
2021-10-25 02:55:52,244 - mmseg - INFO - Epoch [3][100/163]	lr: 9.755e-05, eta: 1:46:05, time: 2.256, data_time: 0.010, memory: 29235, decode.loss_ce: 0.7489, decode.acc_seg: 78.3471, aux.loss_ce: 0.3489, aux.acc_seg: 75.8737, loss: 1.0978, grad_norm: 2.1835
2021-10-25 02:56:14,857 - mmseg - INFO - Epoch [3][110/163]	lr: 9.755e-05, eta: 1:45:43, time: 2.261, data_time: 0.010, memory: 29235, decode.loss_ce: 0.7538, decode.acc_seg: 76.9965, aux.loss_ce: 0.3422, aux.acc_seg: 75.0154, loss: 1.0960, grad_norm: 2.2483
2021-10-25 02:56:37,410 - mmseg - INFO - Epoch [3][120/163]	lr: 9.755e-05, eta: 1:45:21, time: 2.255, data_time: 0.010, memory: 29235, decode.loss_ce: 0.7517, decode.acc_seg: 77.3347, aux.loss_ce: 0.3346, aux.acc_seg: 75.9487, loss: 1.0863, grad_norm: 1.8593
2021-10-25 02:56:59,926 - mmseg - INFO - Epoch [3][130/163]	lr: 9.755e-05, eta: 1:44:59, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.7397, decode.acc_seg: 76.9615, aux.loss_ce: 0.3323, aux.acc_seg: 75.8959, loss: 1.0720, grad_norm: 1.9221
2021-10-25 02:57:22,424 - mmseg - INFO - Epoch [3][140/163]	lr: 9.755e-05, eta: 1:44:37, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.8088, decode.acc_seg: 75.6616, aux.loss_ce: 0.3597, aux.acc_seg: 74.1710, loss: 1.1685, grad_norm: 1.8595
2021-10-25 02:57:44,931 - mmseg - INFO - Epoch [3][150/163]	lr: 9.755e-05, eta: 1:44:15, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.7406, decode.acc_seg: 77.0481, aux.loss_ce: 0.3347, aux.acc_seg: 75.7583, loss: 1.0753, grad_norm: 1.8401
2021-10-25 02:58:07,419 - mmseg - INFO - Epoch [3][160/163]	lr: 9.755e-05, eta: 1:43:52, time: 2.249, data_time: 0.010, memory: 29235, decode.loss_ce: 0.7265, decode.acc_seg: 79.0049, aux.loss_ce: 0.3270, aux.acc_seg: 76.9248, loss: 1.0536, grad_norm: 1.6215
2021-10-25 02:59:09,328 - mmseg - INFO - per class results:
2021-10-25 02:59:09,330 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|   Background  | 84.65 | 96.61 |
| General trash | 17.93 |  27.9 |
|     Paper     | 33.69 | 43.99 |
|   Paper pack  |  0.0  |  0.0  |
|     Metal     |  0.0  |  0.0  |
|     Glass     |  0.0  |  0.0  |
|    Plastic    |  1.43 |  1.5  |
|   Styrofoam   |  0.33 |  0.34 |
|  Plastic bag  |  38.6 | 60.85 |
|    Battery    |  0.0  |  0.0  |
|    Clothing   |  0.0  |  0.0  |
+---------------+-------+-------+
2021-10-25 02:59:09,330 - mmseg - INFO - Summary:
2021-10-25 02:59:09,330 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 79.28 | 16.06 | 21.02 |
+-------+-------+-------+
2021-10-25 02:59:10,904 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_epoch_3.pth.
2021-10-25 02:59:10,904 - mmseg - INFO - Best mIoU is 0.1606 at 3 epoch.
2021-10-25 02:59:10,907 - mmseg - INFO - Exp name: UperCSwinT.py
2021-10-25 02:59:10,908 - mmseg - INFO - Epoch(val) [3][655]	aAcc: 0.7928, mIoU: 0.1606, mAcc: 0.2102, IoU.Background: 0.8465, IoU.General trash: 0.1793, IoU.Paper: 0.3369, IoU.Paper pack: 0.0000, IoU.Metal: 0.0000, IoU.Glass: 0.0000, IoU.Plastic: 0.0143, IoU.Styrofoam: 0.0033, IoU.Plastic bag: 0.3860, IoU.Battery: 0.0000, IoU.Clothing: 0.0000, Acc.Background: 0.9661, Acc.General trash: 0.2790, Acc.Paper: 0.4399, Acc.Paper pack: 0.0000, Acc.Metal: 0.0000, Acc.Glass: 0.0000, Acc.Plastic: 0.0150, Acc.Styrofoam: 0.0034, Acc.Plastic bag: 0.6085, Acc.Battery: 0.0000, Acc.Clothing: 0.0000
2021-10-25 02:59:36,482 - mmseg - INFO - Epoch [4][10/163]	lr: 9.455e-05, eta: 1:43:03, time: 2.556, data_time: 0.304, memory: 29235, decode.loss_ce: 0.6844, decode.acc_seg: 79.0665, aux.loss_ce: 0.3096, aux.acc_seg: 77.4940, loss: 0.9940, grad_norm: 1.9963
2021-10-25 02:59:59,075 - mmseg - INFO - Epoch [4][20/163]	lr: 9.455e-05, eta: 1:42:42, time: 2.259, data_time: 0.011, memory: 29235, decode.loss_ce: 0.7246, decode.acc_seg: 78.0828, aux.loss_ce: 0.3297, aux.acc_seg: 76.5749, loss: 1.0544, grad_norm: 1.9914
2021-10-25 03:00:21,606 - mmseg - INFO - Epoch [4][30/163]	lr: 9.455e-05, eta: 1:42:20, time: 2.253, data_time: 0.010, memory: 29235, decode.loss_ce: 0.7139, decode.acc_seg: 78.2899, aux.loss_ce: 0.3239, aux.acc_seg: 76.6160, loss: 1.0378, grad_norm: 1.8496
2021-10-25 03:00:44,133 - mmseg - INFO - Epoch [4][40/163]	lr: 9.455e-05, eta: 1:41:58, time: 2.253, data_time: 0.010, memory: 29235, decode.loss_ce: 0.7606, decode.acc_seg: 77.3394, aux.loss_ce: 0.3361, aux.acc_seg: 76.3925, loss: 1.0967, grad_norm: 1.6976
2021-10-25 03:01:06,657 - mmseg - INFO - Epoch [4][50/163]	lr: 9.455e-05, eta: 1:41:36, time: 2.252, data_time: 0.010, memory: 29235, decode.loss_ce: 0.6821, decode.acc_seg: 79.4273, aux.loss_ce: 0.3093, aux.acc_seg: 78.0520, loss: 0.9914, grad_norm: 1.8007
2021-10-25 03:01:29,170 - mmseg - INFO - Epoch [4][60/163]	lr: 9.455e-05, eta: 1:41:14, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.7202, decode.acc_seg: 77.6745, aux.loss_ce: 0.3227, aux.acc_seg: 75.9199, loss: 1.0430, grad_norm: 2.3549
2021-10-25 03:01:51,670 - mmseg - INFO - Epoch [4][70/163]	lr: 9.455e-05, eta: 1:40:52, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.7400, decode.acc_seg: 77.6782, aux.loss_ce: 0.3336, aux.acc_seg: 75.4913, loss: 1.0736, grad_norm: 2.0765
2021-10-25 03:02:14,216 - mmseg - INFO - Epoch [4][80/163]	lr: 9.455e-05, eta: 1:40:31, time: 2.255, data_time: 0.010, memory: 29235, decode.loss_ce: 0.6897, decode.acc_seg: 78.7988, aux.loss_ce: 0.3047, aux.acc_seg: 78.1482, loss: 0.9944, grad_norm: 1.6559
2021-10-25 03:02:36,756 - mmseg - INFO - Epoch [4][90/163]	lr: 9.455e-05, eta: 1:40:09, time: 2.254, data_time: 0.010, memory: 29235, decode.loss_ce: 0.7440, decode.acc_seg: 77.4191, aux.loss_ce: 0.3280, aux.acc_seg: 75.8927, loss: 1.0720, grad_norm: 1.8873
2021-10-25 03:02:59,275 - mmseg - INFO - Epoch [4][100/163]	lr: 9.455e-05, eta: 1:39:47, time: 2.252, data_time: 0.010, memory: 29235, decode.loss_ce: 0.6883, decode.acc_seg: 78.7802, aux.loss_ce: 0.3030, aux.acc_seg: 77.3240, loss: 0.9912, grad_norm: 1.8494
2021-10-25 03:03:21,797 - mmseg - INFO - Epoch [4][110/163]	lr: 9.455e-05, eta: 1:39:25, time: 2.252, data_time: 0.011, memory: 29235, decode.loss_ce: 0.7471, decode.acc_seg: 77.2448, aux.loss_ce: 0.3340, aux.acc_seg: 75.2682, loss: 1.0811, grad_norm: 1.8507
2021-10-25 03:03:44,337 - mmseg - INFO - Epoch [4][120/163]	lr: 9.455e-05, eta: 1:39:03, time: 2.254, data_time: 0.010, memory: 29235, decode.loss_ce: 0.7521, decode.acc_seg: 77.3070, aux.loss_ce: 0.3335, aux.acc_seg: 75.1635, loss: 1.0856, grad_norm: 1.7576
2021-10-25 03:04:06,873 - mmseg - INFO - Epoch [4][130/163]	lr: 9.455e-05, eta: 1:38:41, time: 2.254, data_time: 0.010, memory: 29235, decode.loss_ce: 0.6710, decode.acc_seg: 79.2487, aux.loss_ce: 0.2962, aux.acc_seg: 77.1224, loss: 0.9672, grad_norm: 1.7212
2021-10-25 03:04:29,374 - mmseg - INFO - Epoch [4][140/163]	lr: 9.455e-05, eta: 1:38:19, time: 2.250, data_time: 0.011, memory: 29235, decode.loss_ce: 0.6525, decode.acc_seg: 80.3395, aux.loss_ce: 0.2938, aux.acc_seg: 79.1879, loss: 0.9463, grad_norm: 1.7489
2021-10-25 03:04:51,885 - mmseg - INFO - Epoch [4][150/163]	lr: 9.455e-05, eta: 1:37:57, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.7311, decode.acc_seg: 78.1538, aux.loss_ce: 0.3278, aux.acc_seg: 75.9275, loss: 1.0589, grad_norm: 2.0779
2021-10-25 03:05:14,462 - mmseg - INFO - Epoch [4][160/163]	lr: 9.455e-05, eta: 1:37:35, time: 2.258, data_time: 0.010, memory: 29235, decode.loss_ce: 0.6227, decode.acc_seg: 81.1841, aux.loss_ce: 0.2858, aux.acc_seg: 79.2171, loss: 0.9086, grad_norm: 1.8742
2021-10-25 03:06:16,280 - mmseg - INFO - per class results:
2021-10-25 03:06:16,282 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|   Background  | 84.96 | 97.16 |
| General trash | 21.31 | 45.67 |
|     Paper     | 32.13 |  35.8 |
|   Paper pack  |  0.0  |  0.0  |
|     Metal     |  0.0  |  0.0  |
|     Glass     |  0.0  |  0.0  |
|    Plastic    |  5.73 |  6.74 |
|   Styrofoam   |  0.29 |  0.29 |
|  Plastic bag  | 40.21 | 62.42 |
|    Battery    |  0.0  |  0.0  |
|    Clothing   |  0.0  |  0.0  |
+---------------+-------+-------+
2021-10-25 03:06:16,282 - mmseg - INFO - Summary:
2021-10-25 03:06:16,282 - mmseg - INFO - 
+------+-------+-------+
| aAcc |  mIoU |  mAcc |
+------+-------+-------+
| 79.6 | 16.78 | 22.55 |
+------+-------+-------+
2021-10-25 03:06:17,828 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_epoch_4.pth.
2021-10-25 03:06:17,828 - mmseg - INFO - Best mIoU is 0.1678 at 4 epoch.
2021-10-25 03:06:17,832 - mmseg - INFO - Exp name: UperCSwinT.py
2021-10-25 03:06:17,832 - mmseg - INFO - Epoch(val) [4][655]	aAcc: 0.7960, mIoU: 0.1678, mAcc: 0.2255, IoU.Background: 0.8496, IoU.General trash: 0.2131, IoU.Paper: 0.3213, IoU.Paper pack: 0.0000, IoU.Metal: 0.0000, IoU.Glass: 0.0000, IoU.Plastic: 0.0573, IoU.Styrofoam: 0.0029, IoU.Plastic bag: 0.4021, IoU.Battery: 0.0000, IoU.Clothing: 0.0000, Acc.Background: 0.9716, Acc.General trash: 0.4567, Acc.Paper: 0.3580, Acc.Paper pack: 0.0000, Acc.Metal: 0.0000, Acc.Glass: 0.0000, Acc.Plastic: 0.0674, Acc.Styrofoam: 0.0029, Acc.Plastic bag: 0.6242, Acc.Battery: 0.0000, Acc.Clothing: 0.0000
2021-10-25 03:06:43,381 - mmseg - INFO - Epoch [5][10/163]	lr: 9.045e-05, eta: 1:36:52, time: 2.553, data_time: 0.303, memory: 29235, decode.loss_ce: 0.7051, decode.acc_seg: 78.8301, aux.loss_ce: 0.3098, aux.acc_seg: 77.8423, loss: 1.0149, grad_norm: 1.9200
2021-10-25 03:07:05,966 - mmseg - INFO - Epoch [5][20/163]	lr: 9.045e-05, eta: 1:36:30, time: 2.258, data_time: 0.010, memory: 29235, decode.loss_ce: 0.6636, decode.acc_seg: 79.4527, aux.loss_ce: 0.3059, aux.acc_seg: 77.5835, loss: 0.9695, grad_norm: 1.6733
2021-10-25 03:07:28,489 - mmseg - INFO - Epoch [5][30/163]	lr: 9.045e-05, eta: 1:36:08, time: 2.252, data_time: 0.010, memory: 29235, decode.loss_ce: 0.6717, decode.acc_seg: 79.1649, aux.loss_ce: 0.3118, aux.acc_seg: 76.9555, loss: 0.9834, grad_norm: 1.9805
2021-10-25 03:07:51,007 - mmseg - INFO - Epoch [5][40/163]	lr: 9.045e-05, eta: 1:35:47, time: 2.252, data_time: 0.010, memory: 29235, decode.loss_ce: 0.6443, decode.acc_seg: 80.6775, aux.loss_ce: 0.2908, aux.acc_seg: 78.9675, loss: 0.9351, grad_norm: 1.8972
2021-10-25 03:08:13,525 - mmseg - INFO - Epoch [5][50/163]	lr: 9.045e-05, eta: 1:35:25, time: 2.252, data_time: 0.010, memory: 29235, decode.loss_ce: 0.8198, decode.acc_seg: 74.4641, aux.loss_ce: 0.3552, aux.acc_seg: 72.1225, loss: 1.1750, grad_norm: 2.0865
2021-10-25 03:08:36,045 - mmseg - INFO - Epoch [5][60/163]	lr: 9.045e-05, eta: 1:35:03, time: 2.252, data_time: 0.010, memory: 29235, decode.loss_ce: 0.6405, decode.acc_seg: 80.3025, aux.loss_ce: 0.2882, aux.acc_seg: 78.7716, loss: 0.9287, grad_norm: 1.6787
2021-10-25 03:08:58,559 - mmseg - INFO - Epoch [5][70/163]	lr: 9.045e-05, eta: 1:34:41, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.6414, decode.acc_seg: 80.0312, aux.loss_ce: 0.2888, aux.acc_seg: 78.0739, loss: 0.9302, grad_norm: 2.0646
2021-10-25 03:09:21,110 - mmseg - INFO - Epoch [5][80/163]	lr: 9.045e-05, eta: 1:34:19, time: 2.255, data_time: 0.010, memory: 29235, decode.loss_ce: 0.6639, decode.acc_seg: 79.9662, aux.loss_ce: 0.2980, aux.acc_seg: 78.7442, loss: 0.9619, grad_norm: 1.9788
2021-10-25 03:09:43,644 - mmseg - INFO - Epoch [5][90/163]	lr: 9.045e-05, eta: 1:33:57, time: 2.253, data_time: 0.010, memory: 29235, decode.loss_ce: 0.6919, decode.acc_seg: 78.7225, aux.loss_ce: 0.3031, aux.acc_seg: 77.3968, loss: 0.9950, grad_norm: 1.9638
2021-10-25 03:10:06,197 - mmseg - INFO - Epoch [5][100/163]	lr: 9.045e-05, eta: 1:33:35, time: 2.255, data_time: 0.011, memory: 29235, decode.loss_ce: 0.7076, decode.acc_seg: 78.7492, aux.loss_ce: 0.3093, aux.acc_seg: 77.6713, loss: 1.0169, grad_norm: 1.8465
2021-10-25 03:10:28,718 - mmseg - INFO - Epoch [5][110/163]	lr: 9.045e-05, eta: 1:33:13, time: 2.252, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5958, decode.acc_seg: 81.0793, aux.loss_ce: 0.2645, aux.acc_seg: 79.9373, loss: 0.8604, grad_norm: 1.9187
2021-10-25 03:10:51,216 - mmseg - INFO - Epoch [5][120/163]	lr: 9.045e-05, eta: 1:32:51, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.6184, decode.acc_seg: 81.6776, aux.loss_ce: 0.2750, aux.acc_seg: 79.9761, loss: 0.8934, grad_norm: 1.6479
2021-10-25 03:11:13,732 - mmseg - INFO - Epoch [5][130/163]	lr: 9.045e-05, eta: 1:32:29, time: 2.252, data_time: 0.010, memory: 29235, decode.loss_ce: 0.6044, decode.acc_seg: 81.2621, aux.loss_ce: 0.2691, aux.acc_seg: 79.5823, loss: 0.8735, grad_norm: 1.9406
2021-10-25 03:11:36,243 - mmseg - INFO - Epoch [5][140/163]	lr: 9.045e-05, eta: 1:32:07, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.7500, decode.acc_seg: 77.8206, aux.loss_ce: 0.3226, aux.acc_seg: 76.7386, loss: 1.0725, grad_norm: 1.9620
2021-10-25 03:11:58,740 - mmseg - INFO - Epoch [5][150/163]	lr: 9.045e-05, eta: 1:31:45, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.6411, decode.acc_seg: 79.6766, aux.loss_ce: 0.2903, aux.acc_seg: 77.6659, loss: 0.9314, grad_norm: 1.7692
2021-10-25 03:12:21,233 - mmseg - INFO - Epoch [5][160/163]	lr: 9.045e-05, eta: 1:31:23, time: 2.249, data_time: 0.009, memory: 29235, decode.loss_ce: 0.6710, decode.acc_seg: 78.5976, aux.loss_ce: 0.2903, aux.acc_seg: 77.3346, loss: 0.9614, grad_norm: 1.9242
2021-10-25 03:13:23,904 - mmseg - INFO - per class results:
2021-10-25 03:13:23,906 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|   Background  | 85.76 | 94.46 |
| General trash | 13.75 | 18.09 |
|     Paper     | 39.32 | 66.24 |
|   Paper pack  |  1.45 |  1.46 |
|     Metal     |  0.0  |  0.0  |
|     Glass     |  0.06 |  0.06 |
|    Plastic    |  4.8  |  5.36 |
|   Styrofoam   | 20.28 | 32.83 |
|  Plastic bag  | 41.07 | 58.12 |
|    Battery    |  0.0  |  0.0  |
|    Clothing   |  0.0  |  0.0  |
+---------------+-------+-------+
2021-10-25 03:13:23,906 - mmseg - INFO - Summary:
2021-10-25 03:13:23,906 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 79.89 | 18.77 | 25.15 |
+-------+-------+-------+
2021-10-25 03:13:25,464 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_epoch_5.pth.
2021-10-25 03:13:25,464 - mmseg - INFO - Best mIoU is 0.1877 at 5 epoch.
2021-10-25 03:13:25,468 - mmseg - INFO - Exp name: UperCSwinT.py
2021-10-25 03:13:25,468 - mmseg - INFO - Epoch(val) [5][655]	aAcc: 0.7989, mIoU: 0.1877, mAcc: 0.2515, IoU.Background: 0.8576, IoU.General trash: 0.1375, IoU.Paper: 0.3932, IoU.Paper pack: 0.0145, IoU.Metal: 0.0000, IoU.Glass: 0.0006, IoU.Plastic: 0.0480, IoU.Styrofoam: 0.2028, IoU.Plastic bag: 0.4107, IoU.Battery: 0.0000, IoU.Clothing: 0.0000, Acc.Background: 0.9446, Acc.General trash: 0.1809, Acc.Paper: 0.6624, Acc.Paper pack: 0.0146, Acc.Metal: 0.0000, Acc.Glass: 0.0006, Acc.Plastic: 0.0536, Acc.Styrofoam: 0.3283, Acc.Plastic bag: 0.5812, Acc.Battery: 0.0000, Acc.Clothing: 0.0000
2021-10-25 03:13:51,006 - mmseg - INFO - Epoch [6][10/163]	lr: 8.536e-05, eta: 1:30:43, time: 2.552, data_time: 0.300, memory: 29235, decode.loss_ce: 0.6338, decode.acc_seg: 81.0617, aux.loss_ce: 0.2849, aux.acc_seg: 78.7314, loss: 0.9187, grad_norm: 2.1478
2021-10-25 03:14:13,598 - mmseg - INFO - Epoch [6][20/163]	lr: 8.536e-05, eta: 1:30:22, time: 2.259, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5796, decode.acc_seg: 82.5345, aux.loss_ce: 0.2647, aux.acc_seg: 80.8384, loss: 0.8444, grad_norm: 1.7434
2021-10-25 03:14:36,112 - mmseg - INFO - Epoch [6][30/163]	lr: 8.536e-05, eta: 1:30:00, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.6437, decode.acc_seg: 80.4707, aux.loss_ce: 0.2820, aux.acc_seg: 78.7430, loss: 0.9257, grad_norm: 1.9731
2021-10-25 03:14:58,623 - mmseg - INFO - Epoch [6][40/163]	lr: 8.536e-05, eta: 1:29:38, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.6538, decode.acc_seg: 79.2366, aux.loss_ce: 0.2913, aux.acc_seg: 78.1701, loss: 0.9451, grad_norm: 1.8033
2021-10-25 03:15:21,154 - mmseg - INFO - Epoch [6][50/163]	lr: 8.536e-05, eta: 1:29:16, time: 2.253, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5835, decode.acc_seg: 82.3292, aux.loss_ce: 0.2628, aux.acc_seg: 80.9652, loss: 0.8463, grad_norm: 2.4994
2021-10-25 03:15:43,663 - mmseg - INFO - Epoch [6][60/163]	lr: 8.536e-05, eta: 1:28:54, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.6414, decode.acc_seg: 80.0790, aux.loss_ce: 0.2821, aux.acc_seg: 78.7321, loss: 0.9235, grad_norm: 2.2421
2021-10-25 03:16:06,199 - mmseg - INFO - Epoch [6][70/163]	lr: 8.536e-05, eta: 1:28:32, time: 2.254, data_time: 0.010, memory: 29235, decode.loss_ce: 0.6138, decode.acc_seg: 81.0075, aux.loss_ce: 0.2746, aux.acc_seg: 79.3984, loss: 0.8884, grad_norm: 1.9101
2021-10-25 03:16:28,725 - mmseg - INFO - Epoch [6][80/163]	lr: 8.536e-05, eta: 1:28:10, time: 2.253, data_time: 0.010, memory: 29235, decode.loss_ce: 0.7082, decode.acc_seg: 77.6615, aux.loss_ce: 0.3057, aux.acc_seg: 76.7459, loss: 1.0139, grad_norm: 2.4828
2021-10-25 03:16:51,234 - mmseg - INFO - Epoch [6][90/163]	lr: 8.536e-05, eta: 1:27:48, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.6936, decode.acc_seg: 78.6347, aux.loss_ce: 0.3101, aux.acc_seg: 76.6086, loss: 1.0038, grad_norm: 2.0151
2021-10-25 03:17:13,752 - mmseg - INFO - Epoch [6][100/163]	lr: 8.536e-05, eta: 1:27:26, time: 2.252, data_time: 0.011, memory: 29235, decode.loss_ce: 0.6253, decode.acc_seg: 80.0942, aux.loss_ce: 0.2780, aux.acc_seg: 78.8812, loss: 0.9032, grad_norm: 2.1978
2021-10-25 03:17:36,256 - mmseg - INFO - Epoch [6][110/163]	lr: 8.536e-05, eta: 1:27:04, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.6906, decode.acc_seg: 78.5366, aux.loss_ce: 0.3006, aux.acc_seg: 77.2470, loss: 0.9912, grad_norm: 2.1085
2021-10-25 03:17:58,769 - mmseg - INFO - Epoch [6][120/163]	lr: 8.536e-05, eta: 1:26:42, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.6732, decode.acc_seg: 79.4211, aux.loss_ce: 0.2998, aux.acc_seg: 77.9543, loss: 0.9730, grad_norm: 1.9401
2021-10-25 03:18:21,391 - mmseg - INFO - Epoch [6][130/163]	lr: 8.536e-05, eta: 1:26:20, time: 2.262, data_time: 0.011, memory: 29235, decode.loss_ce: 0.5915, decode.acc_seg: 81.8966, aux.loss_ce: 0.2666, aux.acc_seg: 80.6491, loss: 0.8581, grad_norm: 1.9570
2021-10-25 03:18:43,902 - mmseg - INFO - Epoch [6][140/163]	lr: 8.536e-05, eta: 1:25:58, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.6034, decode.acc_seg: 81.6106, aux.loss_ce: 0.2688, aux.acc_seg: 80.1431, loss: 0.8722, grad_norm: 2.0313
2021-10-25 03:19:06,427 - mmseg - INFO - Epoch [6][150/163]	lr: 8.536e-05, eta: 1:25:36, time: 2.252, data_time: 0.010, memory: 29235, decode.loss_ce: 0.6585, decode.acc_seg: 78.7498, aux.loss_ce: 0.2950, aux.acc_seg: 76.1632, loss: 0.9535, grad_norm: 2.1100
2021-10-25 03:19:28,927 - mmseg - INFO - Epoch [6][160/163]	lr: 8.536e-05, eta: 1:25:14, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.7132, decode.acc_seg: 78.5802, aux.loss_ce: 0.3124, aux.acc_seg: 76.0964, loss: 1.0256, grad_norm: 2.2093
2021-10-25 03:20:32,327 - mmseg - INFO - per class results:
2021-10-25 03:20:32,328 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|   Background  | 86.27 | 96.59 |
| General trash | 21.73 | 36.05 |
|     Paper     | 38.48 | 51.25 |
|   Paper pack  |  0.02 |  0.02 |
|     Metal     |  0.0  |  0.0  |
|     Glass     |  4.78 |  5.87 |
|    Plastic    |  4.78 |  6.12 |
|   Styrofoam   |  9.65 | 10.98 |
|  Plastic bag  |  44.7 | 64.64 |
|    Battery    |  0.0  |  0.0  |
|    Clothing   |  0.0  |  0.0  |
+---------------+-------+-------+
2021-10-25 03:20:32,328 - mmseg - INFO - Summary:
2021-10-25 03:20:32,329 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 80.88 | 19.13 | 24.68 |
+-------+-------+-------+
2021-10-25 03:20:33,898 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_epoch_6.pth.
2021-10-25 03:20:33,898 - mmseg - INFO - Best mIoU is 0.1913 at 6 epoch.
2021-10-25 03:20:33,902 - mmseg - INFO - Exp name: UperCSwinT.py
2021-10-25 03:20:33,902 - mmseg - INFO - Epoch(val) [6][655]	aAcc: 0.8088, mIoU: 0.1913, mAcc: 0.2468, IoU.Background: 0.8627, IoU.General trash: 0.2173, IoU.Paper: 0.3848, IoU.Paper pack: 0.0002, IoU.Metal: 0.0000, IoU.Glass: 0.0478, IoU.Plastic: 0.0478, IoU.Styrofoam: 0.0965, IoU.Plastic bag: 0.4470, IoU.Battery: 0.0000, IoU.Clothing: 0.0000, Acc.Background: 0.9659, Acc.General trash: 0.3605, Acc.Paper: 0.5125, Acc.Paper pack: 0.0002, Acc.Metal: 0.0000, Acc.Glass: 0.0587, Acc.Plastic: 0.0612, Acc.Styrofoam: 0.1098, Acc.Plastic bag: 0.6464, Acc.Battery: 0.0000, Acc.Clothing: 0.0000
2021-10-25 03:20:59,601 - mmseg - INFO - Epoch [7][10/163]	lr: 7.939e-05, eta: 1:24:37, time: 2.568, data_time: 0.323, memory: 29235, decode.loss_ce: 0.6106, decode.acc_seg: 81.2845, aux.loss_ce: 0.2743, aux.acc_seg: 79.2076, loss: 0.8849, grad_norm: 2.1176
2021-10-25 03:21:22,188 - mmseg - INFO - Epoch [7][20/163]	lr: 7.939e-05, eta: 1:24:15, time: 2.259, data_time: 0.010, memory: 29235, decode.loss_ce: 0.6545, decode.acc_seg: 79.1282, aux.loss_ce: 0.2899, aux.acc_seg: 78.5660, loss: 0.9445, grad_norm: 2.0120
2021-10-25 03:21:44,758 - mmseg - INFO - Epoch [7][30/163]	lr: 7.939e-05, eta: 1:23:53, time: 2.257, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5961, decode.acc_seg: 81.7688, aux.loss_ce: 0.2697, aux.acc_seg: 79.5375, loss: 0.8658, grad_norm: 1.9511
2021-10-25 03:22:07,283 - mmseg - INFO - Epoch [7][40/163]	lr: 7.939e-05, eta: 1:23:31, time: 2.252, data_time: 0.011, memory: 29235, decode.loss_ce: 0.6230, decode.acc_seg: 80.4328, aux.loss_ce: 0.2778, aux.acc_seg: 78.7920, loss: 0.9008, grad_norm: 2.5006
2021-10-25 03:22:29,802 - mmseg - INFO - Epoch [7][50/163]	lr: 7.939e-05, eta: 1:23:09, time: 2.252, data_time: 0.011, memory: 29235, decode.loss_ce: 0.5515, decode.acc_seg: 83.7909, aux.loss_ce: 0.2521, aux.acc_seg: 81.0518, loss: 0.8036, grad_norm: 1.9835
2021-10-25 03:22:52,378 - mmseg - INFO - Epoch [7][60/163]	lr: 7.939e-05, eta: 1:22:48, time: 2.258, data_time: 0.011, memory: 29235, decode.loss_ce: 0.6277, decode.acc_seg: 80.6629, aux.loss_ce: 0.2685, aux.acc_seg: 79.8493, loss: 0.8962, grad_norm: 2.1330
2021-10-25 03:23:14,874 - mmseg - INFO - Epoch [7][70/163]	lr: 7.939e-05, eta: 1:22:25, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.6125, decode.acc_seg: 80.7623, aux.loss_ce: 0.2758, aux.acc_seg: 78.9070, loss: 0.8883, grad_norm: 2.0098
2021-10-25 03:23:37,407 - mmseg - INFO - Epoch [7][80/163]	lr: 7.939e-05, eta: 1:22:03, time: 2.253, data_time: 0.010, memory: 29235, decode.loss_ce: 0.6166, decode.acc_seg: 80.8096, aux.loss_ce: 0.2744, aux.acc_seg: 78.6570, loss: 0.8910, grad_norm: 1.9825
2021-10-25 03:23:59,941 - mmseg - INFO - Epoch [7][90/163]	lr: 7.939e-05, eta: 1:21:41, time: 2.253, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5988, decode.acc_seg: 81.0327, aux.loss_ce: 0.2664, aux.acc_seg: 79.2749, loss: 0.8652, grad_norm: 2.2085
2021-10-25 03:24:22,442 - mmseg - INFO - Epoch [7][100/163]	lr: 7.939e-05, eta: 1:21:19, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.6442, decode.acc_seg: 79.5227, aux.loss_ce: 0.2806, aux.acc_seg: 79.0078, loss: 0.9248, grad_norm: 2.0898
2021-10-25 03:24:44,943 - mmseg - INFO - Epoch [7][110/163]	lr: 7.939e-05, eta: 1:20:57, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.6266, decode.acc_seg: 80.9672, aux.loss_ce: 0.2741, aux.acc_seg: 79.7598, loss: 0.9007, grad_norm: 1.9905
2021-10-25 03:25:07,463 - mmseg - INFO - Epoch [7][120/163]	lr: 7.939e-05, eta: 1:20:35, time: 2.252, data_time: 0.011, memory: 29235, decode.loss_ce: 0.5889, decode.acc_seg: 81.2911, aux.loss_ce: 0.2600, aux.acc_seg: 80.2037, loss: 0.8489, grad_norm: 2.0026
2021-10-25 03:25:29,977 - mmseg - INFO - Epoch [7][130/163]	lr: 7.939e-05, eta: 1:20:13, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5982, decode.acc_seg: 80.5439, aux.loss_ce: 0.2692, aux.acc_seg: 79.1092, loss: 0.8673, grad_norm: 2.0886
2021-10-25 03:25:52,479 - mmseg - INFO - Epoch [7][140/163]	lr: 7.939e-05, eta: 1:19:51, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.6289, decode.acc_seg: 81.0985, aux.loss_ce: 0.2783, aux.acc_seg: 79.0315, loss: 0.9072, grad_norm: 1.9562
2021-10-25 03:26:14,976 - mmseg - INFO - Epoch [7][150/163]	lr: 7.939e-05, eta: 1:19:29, time: 2.250, data_time: 0.011, memory: 29235, decode.loss_ce: 0.5912, decode.acc_seg: 81.4154, aux.loss_ce: 0.2630, aux.acc_seg: 79.7893, loss: 0.8543, grad_norm: 1.9793
2021-10-25 03:26:37,462 - mmseg - INFO - Epoch [7][160/163]	lr: 7.939e-05, eta: 1:19:07, time: 2.249, data_time: 0.010, memory: 29235, decode.loss_ce: 0.7339, decode.acc_seg: 78.2911, aux.loss_ce: 0.3202, aux.acc_seg: 76.2767, loss: 1.0541, grad_norm: 2.8716
2021-10-25 03:27:40,097 - mmseg - INFO - per class results:
2021-10-25 03:27:40,098 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|   Background  | 86.69 | 94.89 |
| General trash |  7.1  |  7.61 |
|     Paper     |  39.9 | 74.21 |
|   Paper pack  |  1.17 |  1.19 |
|     Metal     |  0.51 |  0.52 |
|     Glass     |  6.89 | 11.46 |
|    Plastic    | 11.09 | 16.25 |
|   Styrofoam   | 12.75 | 14.76 |
|  Plastic bag  | 45.08 | 55.87 |
|    Battery    |  0.0  |  0.0  |
|    Clothing   |  0.0  |  0.0  |
+---------------+-------+-------+
2021-10-25 03:27:40,099 - mmseg - INFO - Summary:
2021-10-25 03:27:40,099 - mmseg - INFO - 
+-------+------+-------+
|  aAcc | mIoU |  mAcc |
+-------+------+-------+
| 80.54 | 19.2 | 25.16 |
+-------+------+-------+
2021-10-25 03:27:41,680 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_epoch_7.pth.
2021-10-25 03:27:41,681 - mmseg - INFO - Best mIoU is 0.1920 at 7 epoch.
2021-10-25 03:27:41,684 - mmseg - INFO - Exp name: UperCSwinT.py
2021-10-25 03:27:41,684 - mmseg - INFO - Epoch(val) [7][655]	aAcc: 0.8054, mIoU: 0.1920, mAcc: 0.2516, IoU.Background: 0.8669, IoU.General trash: 0.0710, IoU.Paper: 0.3990, IoU.Paper pack: 0.0117, IoU.Metal: 0.0051, IoU.Glass: 0.0689, IoU.Plastic: 0.1109, IoU.Styrofoam: 0.1275, IoU.Plastic bag: 0.4508, IoU.Battery: 0.0000, IoU.Clothing: 0.0000, Acc.Background: 0.9489, Acc.General trash: 0.0761, Acc.Paper: 0.7421, Acc.Paper pack: 0.0119, Acc.Metal: 0.0052, Acc.Glass: 0.1146, Acc.Plastic: 0.1625, Acc.Styrofoam: 0.1476, Acc.Plastic bag: 0.5587, Acc.Battery: 0.0000, Acc.Clothing: 0.0000
2021-10-25 03:28:07,423 - mmseg - INFO - Epoch [8][10/163]	lr: 7.270e-05, eta: 1:18:31, time: 2.572, data_time: 0.320, memory: 29235, decode.loss_ce: 0.5768, decode.acc_seg: 81.9045, aux.loss_ce: 0.2590, aux.acc_seg: 80.2027, loss: 0.8359, grad_norm: 2.0854
2021-10-25 03:28:29,931 - mmseg - INFO - Epoch [8][20/163]	lr: 7.270e-05, eta: 1:18:09, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.6111, decode.acc_seg: 80.6607, aux.loss_ce: 0.2757, aux.acc_seg: 79.1060, loss: 0.8868, grad_norm: 1.9023
2021-10-25 03:28:52,428 - mmseg - INFO - Epoch [8][30/163]	lr: 7.270e-05, eta: 1:17:47, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.6081, decode.acc_seg: 81.2751, aux.loss_ce: 0.2764, aux.acc_seg: 78.8546, loss: 0.8845, grad_norm: 1.8168
2021-10-25 03:29:14,965 - mmseg - INFO - Epoch [8][40/163]	lr: 7.270e-05, eta: 1:17:25, time: 2.254, data_time: 0.011, memory: 29235, decode.loss_ce: 0.5950, decode.acc_seg: 81.2777, aux.loss_ce: 0.2730, aux.acc_seg: 78.8263, loss: 0.8680, grad_norm: 2.1775
2021-10-25 03:29:37,504 - mmseg - INFO - Epoch [8][50/163]	lr: 7.270e-05, eta: 1:17:03, time: 2.254, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5895, decode.acc_seg: 81.7296, aux.loss_ce: 0.2625, aux.acc_seg: 80.6998, loss: 0.8520, grad_norm: 2.2190
2021-10-25 03:30:00,003 - mmseg - INFO - Epoch [8][60/163]	lr: 7.270e-05, eta: 1:16:41, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5991, decode.acc_seg: 81.6384, aux.loss_ce: 0.2719, aux.acc_seg: 79.6159, loss: 0.8710, grad_norm: 2.1875
2021-10-25 03:30:22,483 - mmseg - INFO - Epoch [8][70/163]	lr: 7.270e-05, eta: 1:16:19, time: 2.248, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5978, decode.acc_seg: 81.4902, aux.loss_ce: 0.2733, aux.acc_seg: 78.8116, loss: 0.8711, grad_norm: 2.1078
2021-10-25 03:30:44,994 - mmseg - INFO - Epoch [8][80/163]	lr: 7.270e-05, eta: 1:15:57, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.6225, decode.acc_seg: 81.1769, aux.loss_ce: 0.2788, aux.acc_seg: 79.1301, loss: 0.9013, grad_norm: 2.1481
2021-10-25 03:31:07,507 - mmseg - INFO - Epoch [8][90/163]	lr: 7.270e-05, eta: 1:15:35, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.6006, decode.acc_seg: 80.4825, aux.loss_ce: 0.2694, aux.acc_seg: 79.4781, loss: 0.8700, grad_norm: 2.2160
2021-10-25 03:31:30,063 - mmseg - INFO - Epoch [8][100/163]	lr: 7.270e-05, eta: 1:15:13, time: 2.256, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5471, decode.acc_seg: 82.6933, aux.loss_ce: 0.2503, aux.acc_seg: 80.9748, loss: 0.7974, grad_norm: 1.9461
2021-10-25 03:31:52,592 - mmseg - INFO - Epoch [8][110/163]	lr: 7.270e-05, eta: 1:14:51, time: 2.253, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5656, decode.acc_seg: 82.6769, aux.loss_ce: 0.2596, aux.acc_seg: 80.8325, loss: 0.8252, grad_norm: 2.0679
2021-10-25 03:32:15,123 - mmseg - INFO - Epoch [8][120/163]	lr: 7.270e-05, eta: 1:14:29, time: 2.253, data_time: 0.011, memory: 29235, decode.loss_ce: 0.6425, decode.acc_seg: 80.9455, aux.loss_ce: 0.2850, aux.acc_seg: 79.2852, loss: 0.9276, grad_norm: 2.5191
2021-10-25 03:32:37,629 - mmseg - INFO - Epoch [8][130/163]	lr: 7.270e-05, eta: 1:14:07, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.6152, decode.acc_seg: 80.9842, aux.loss_ce: 0.2744, aux.acc_seg: 79.2862, loss: 0.8896, grad_norm: 2.2468
2021-10-25 03:33:00,133 - mmseg - INFO - Epoch [8][140/163]	lr: 7.270e-05, eta: 1:13:45, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5698, decode.acc_seg: 82.2407, aux.loss_ce: 0.2530, aux.acc_seg: 80.6726, loss: 0.8228, grad_norm: 2.1394
2021-10-25 03:33:22,711 - mmseg - INFO - Epoch [8][150/163]	lr: 7.270e-05, eta: 1:13:23, time: 2.258, data_time: 0.010, memory: 29235, decode.loss_ce: 0.6298, decode.acc_seg: 80.2139, aux.loss_ce: 0.2761, aux.acc_seg: 78.9898, loss: 0.9059, grad_norm: 2.8214
2021-10-25 03:33:45,191 - mmseg - INFO - Epoch [8][160/163]	lr: 7.270e-05, eta: 1:13:00, time: 2.248, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5152, decode.acc_seg: 83.3699, aux.loss_ce: 0.2334, aux.acc_seg: 81.5991, loss: 0.7486, grad_norm: 2.1591
2021-10-25 03:34:46,672 - mmseg - INFO - per class results:
2021-10-25 03:34:46,674 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|   Background  | 86.73 |  97.6 |
| General trash | 17.64 | 24.18 |
|     Paper     | 40.31 | 50.87 |
|   Paper pack  |  0.01 |  0.01 |
|     Metal     |  0.03 |  0.03 |
|     Glass     |  0.03 |  0.03 |
|    Plastic    | 14.22 |  26.7 |
|   Styrofoam   | 11.97 | 12.97 |
|  Plastic bag  | 47.33 | 63.75 |
|    Battery    |  0.0  |  0.0  |
|    Clothing   |  0.34 |  0.34 |
+---------------+-------+-------+
2021-10-25 03:34:46,674 - mmseg - INFO - Summary:
2021-10-25 03:34:46,675 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 81.68 | 19.87 | 25.14 |
+-------+-------+-------+
2021-10-25 03:34:48,243 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_epoch_8.pth.
2021-10-25 03:34:48,243 - mmseg - INFO - Best mIoU is 0.1987 at 8 epoch.
2021-10-25 03:34:48,247 - mmseg - INFO - Exp name: UperCSwinT.py
2021-10-25 03:34:48,247 - mmseg - INFO - Epoch(val) [8][655]	aAcc: 0.8168, mIoU: 0.1987, mAcc: 0.2514, IoU.Background: 0.8673, IoU.General trash: 0.1764, IoU.Paper: 0.4031, IoU.Paper pack: 0.0001, IoU.Metal: 0.0003, IoU.Glass: 0.0003, IoU.Plastic: 0.1422, IoU.Styrofoam: 0.1197, IoU.Plastic bag: 0.4733, IoU.Battery: 0.0000, IoU.Clothing: 0.0034, Acc.Background: 0.9760, Acc.General trash: 0.2418, Acc.Paper: 0.5087, Acc.Paper pack: 0.0001, Acc.Metal: 0.0003, Acc.Glass: 0.0003, Acc.Plastic: 0.2670, Acc.Styrofoam: 0.1297, Acc.Plastic bag: 0.6375, Acc.Battery: 0.0000, Acc.Clothing: 0.0034
2021-10-25 03:35:13,903 - mmseg - INFO - Epoch [9][10/163]	lr: 6.545e-05, eta: 1:12:26, time: 2.564, data_time: 0.311, memory: 29235, decode.loss_ce: 0.6894, decode.acc_seg: 78.9283, aux.loss_ce: 0.3084, aux.acc_seg: 76.8366, loss: 0.9977, grad_norm: 2.2346
2021-10-25 03:35:36,439 - mmseg - INFO - Epoch [9][20/163]	lr: 6.545e-05, eta: 1:12:04, time: 2.254, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5530, decode.acc_seg: 82.1565, aux.loss_ce: 0.2482, aux.acc_seg: 81.2324, loss: 0.8012, grad_norm: 2.0643
2021-10-25 03:35:58,955 - mmseg - INFO - Epoch [9][30/163]	lr: 6.545e-05, eta: 1:11:42, time: 2.252, data_time: 0.011, memory: 29235, decode.loss_ce: 0.5489, decode.acc_seg: 82.7194, aux.loss_ce: 0.2571, aux.acc_seg: 80.4162, loss: 0.8059, grad_norm: 1.9100
2021-10-25 03:36:21,464 - mmseg - INFO - Epoch [9][40/163]	lr: 6.545e-05, eta: 1:11:20, time: 2.251, data_time: 0.011, memory: 29235, decode.loss_ce: 0.4970, decode.acc_seg: 84.1325, aux.loss_ce: 0.2267, aux.acc_seg: 82.1721, loss: 0.7236, grad_norm: 1.9283
2021-10-25 03:36:43,983 - mmseg - INFO - Epoch [9][50/163]	lr: 6.545e-05, eta: 1:10:58, time: 2.252, data_time: 0.011, memory: 29235, decode.loss_ce: 0.6047, decode.acc_seg: 81.1894, aux.loss_ce: 0.2750, aux.acc_seg: 79.3539, loss: 0.8796, grad_norm: 2.0951
2021-10-25 03:37:06,493 - mmseg - INFO - Epoch [9][60/163]	lr: 6.545e-05, eta: 1:10:36, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4937, decode.acc_seg: 84.2614, aux.loss_ce: 0.2252, aux.acc_seg: 82.6486, loss: 0.7190, grad_norm: 1.8890
2021-10-25 03:37:28,994 - mmseg - INFO - Epoch [9][70/163]	lr: 6.545e-05, eta: 1:10:14, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.6226, decode.acc_seg: 80.1752, aux.loss_ce: 0.2737, aux.acc_seg: 79.3386, loss: 0.8963, grad_norm: 2.4079
2021-10-25 03:37:51,492 - mmseg - INFO - Epoch [9][80/163]	lr: 6.545e-05, eta: 1:09:51, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5662, decode.acc_seg: 82.1251, aux.loss_ce: 0.2635, aux.acc_seg: 79.6945, loss: 0.8297, grad_norm: 2.5174
2021-10-25 03:38:13,994 - mmseg - INFO - Epoch [9][90/163]	lr: 6.545e-05, eta: 1:09:29, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.6224, decode.acc_seg: 81.3121, aux.loss_ce: 0.2767, aux.acc_seg: 79.4109, loss: 0.8991, grad_norm: 2.5893
2021-10-25 03:38:36,525 - mmseg - INFO - Epoch [9][100/163]	lr: 6.545e-05, eta: 1:09:07, time: 2.253, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5604, decode.acc_seg: 82.3574, aux.loss_ce: 0.2473, aux.acc_seg: 80.8694, loss: 0.8077, grad_norm: 2.1934
2021-10-25 03:38:59,035 - mmseg - INFO - Epoch [9][110/163]	lr: 6.545e-05, eta: 1:08:45, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5401, decode.acc_seg: 83.0706, aux.loss_ce: 0.2477, aux.acc_seg: 81.2302, loss: 0.7878, grad_norm: 2.1573
2021-10-25 03:39:21,538 - mmseg - INFO - Epoch [9][120/163]	lr: 6.545e-05, eta: 1:08:23, time: 2.250, data_time: 0.011, memory: 29235, decode.loss_ce: 0.6420, decode.acc_seg: 79.6636, aux.loss_ce: 0.2892, aux.acc_seg: 78.1843, loss: 0.9312, grad_norm: 2.5052
2021-10-25 03:39:44,063 - mmseg - INFO - Epoch [9][130/163]	lr: 6.545e-05, eta: 1:08:01, time: 2.253, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5270, decode.acc_seg: 83.8465, aux.loss_ce: 0.2376, aux.acc_seg: 82.1885, loss: 0.7646, grad_norm: 2.0176
2021-10-25 03:40:06,585 - mmseg - INFO - Epoch [9][140/163]	lr: 6.545e-05, eta: 1:07:39, time: 2.252, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5762, decode.acc_seg: 81.7653, aux.loss_ce: 0.2573, aux.acc_seg: 80.3065, loss: 0.8335, grad_norm: 2.2201
2021-10-25 03:40:29,084 - mmseg - INFO - Epoch [9][150/163]	lr: 6.545e-05, eta: 1:07:17, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5407, decode.acc_seg: 83.7404, aux.loss_ce: 0.2414, aux.acc_seg: 82.1482, loss: 0.7821, grad_norm: 1.9228
2021-10-25 03:40:51,549 - mmseg - INFO - Epoch [9][160/163]	lr: 6.545e-05, eta: 1:06:54, time: 2.246, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5382, decode.acc_seg: 83.0426, aux.loss_ce: 0.2416, aux.acc_seg: 81.8436, loss: 0.7798, grad_norm: 2.0210
2021-10-25 03:41:54,293 - mmseg - INFO - per class results:
2021-10-25 03:41:54,294 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|   Background  | 87.36 | 96.82 |
| General trash |  21.8 | 30.82 |
|     Paper     | 45.02 | 63.12 |
|   Paper pack  |  3.51 |  3.63 |
|     Metal     |  0.23 |  0.23 |
|     Glass     |  3.02 |  3.38 |
|    Plastic    |  6.19 |  7.66 |
|   Styrofoam   | 21.78 | 35.34 |
|  Plastic bag  | 50.68 | 66.23 |
|    Battery    |  0.0  |  0.0  |
|    Clothing   |  0.35 |  0.36 |
+---------------+-------+-------+
2021-10-25 03:41:54,294 - mmseg - INFO - Summary:
2021-10-25 03:41:54,294 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 82.61 | 21.81 | 27.96 |
+-------+-------+-------+
2021-10-25 03:41:55,838 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_epoch_9.pth.
2021-10-25 03:41:55,838 - mmseg - INFO - Best mIoU is 0.2181 at 9 epoch.
2021-10-25 03:41:55,842 - mmseg - INFO - Exp name: UperCSwinT.py
2021-10-25 03:41:55,842 - mmseg - INFO - Epoch(val) [9][655]	aAcc: 0.8261, mIoU: 0.2181, mAcc: 0.2796, IoU.Background: 0.8736, IoU.General trash: 0.2180, IoU.Paper: 0.4502, IoU.Paper pack: 0.0351, IoU.Metal: 0.0023, IoU.Glass: 0.0302, IoU.Plastic: 0.0619, IoU.Styrofoam: 0.2178, IoU.Plastic bag: 0.5068, IoU.Battery: 0.0000, IoU.Clothing: 0.0035, Acc.Background: 0.9682, Acc.General trash: 0.3082, Acc.Paper: 0.6312, Acc.Paper pack: 0.0363, Acc.Metal: 0.0023, Acc.Glass: 0.0338, Acc.Plastic: 0.0766, Acc.Styrofoam: 0.3534, Acc.Plastic bag: 0.6623, Acc.Battery: 0.0000, Acc.Clothing: 0.0036
2021-10-25 03:42:21,261 - mmseg - INFO - Epoch [10][10/163]	lr: 5.782e-05, eta: 1:06:21, time: 2.540, data_time: 0.290, memory: 29235, decode.loss_ce: 0.4995, decode.acc_seg: 84.0603, aux.loss_ce: 0.2343, aux.acc_seg: 82.0877, loss: 0.7338, grad_norm: 1.9119
2021-10-25 03:42:43,803 - mmseg - INFO - Epoch [10][20/163]	lr: 5.782e-05, eta: 1:05:59, time: 2.254, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5455, decode.acc_seg: 82.6685, aux.loss_ce: 0.2518, aux.acc_seg: 80.4913, loss: 0.7974, grad_norm: 2.1065
2021-10-25 03:43:06,319 - mmseg - INFO - Epoch [10][30/163]	lr: 5.782e-05, eta: 1:05:37, time: 2.252, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5547, decode.acc_seg: 83.4575, aux.loss_ce: 0.2507, aux.acc_seg: 80.8847, loss: 0.8054, grad_norm: 2.1242
2021-10-25 03:43:28,812 - mmseg - INFO - Epoch [10][40/163]	lr: 5.782e-05, eta: 1:05:14, time: 2.249, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5228, decode.acc_seg: 83.1895, aux.loss_ce: 0.2408, aux.acc_seg: 81.2858, loss: 0.7637, grad_norm: 1.9870
2021-10-25 03:43:51,315 - mmseg - INFO - Epoch [10][50/163]	lr: 5.782e-05, eta: 1:04:52, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5771, decode.acc_seg: 81.6836, aux.loss_ce: 0.2616, aux.acc_seg: 79.9397, loss: 0.8387, grad_norm: 2.5638
2021-10-25 03:44:13,828 - mmseg - INFO - Epoch [10][60/163]	lr: 5.782e-05, eta: 1:04:30, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5528, decode.acc_seg: 82.4157, aux.loss_ce: 0.2573, aux.acc_seg: 80.5009, loss: 0.8101, grad_norm: 2.1125
2021-10-25 03:44:36,331 - mmseg - INFO - Epoch [10][70/163]	lr: 5.782e-05, eta: 1:04:08, time: 2.250, data_time: 0.011, memory: 29235, decode.loss_ce: 0.5933, decode.acc_seg: 82.1459, aux.loss_ce: 0.2689, aux.acc_seg: 80.3307, loss: 0.8622, grad_norm: 2.1403
2021-10-25 03:44:58,820 - mmseg - INFO - Epoch [10][80/163]	lr: 5.782e-05, eta: 1:03:46, time: 2.249, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5582, decode.acc_seg: 82.2161, aux.loss_ce: 0.2532, aux.acc_seg: 80.4217, loss: 0.8114, grad_norm: 2.2954
2021-10-25 03:45:21,313 - mmseg - INFO - Epoch [10][90/163]	lr: 5.782e-05, eta: 1:03:24, time: 2.249, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4880, decode.acc_seg: 84.1985, aux.loss_ce: 0.2189, aux.acc_seg: 83.1594, loss: 0.7069, grad_norm: 2.1075
2021-10-25 03:45:43,816 - mmseg - INFO - Epoch [10][100/163]	lr: 5.782e-05, eta: 1:03:02, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5642, decode.acc_seg: 82.0701, aux.loss_ce: 0.2585, aux.acc_seg: 80.0050, loss: 0.8227, grad_norm: 2.1979
2021-10-25 03:46:06,323 - mmseg - INFO - Epoch [10][110/163]	lr: 5.782e-05, eta: 1:02:39, time: 2.251, data_time: 0.011, memory: 29235, decode.loss_ce: 0.5553, decode.acc_seg: 82.7415, aux.loss_ce: 0.2468, aux.acc_seg: 81.1358, loss: 0.8021, grad_norm: 2.3485
2021-10-25 03:46:28,853 - mmseg - INFO - Epoch [10][120/163]	lr: 5.782e-05, eta: 1:02:17, time: 2.253, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5948, decode.acc_seg: 80.9882, aux.loss_ce: 0.2627, aux.acc_seg: 79.8948, loss: 0.8575, grad_norm: 2.2188
2021-10-25 03:46:51,384 - mmseg - INFO - Epoch [10][130/163]	lr: 5.782e-05, eta: 1:01:55, time: 2.253, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5434, decode.acc_seg: 83.2460, aux.loss_ce: 0.2490, aux.acc_seg: 81.4373, loss: 0.7924, grad_norm: 2.3389
2021-10-25 03:47:13,861 - mmseg - INFO - Epoch [10][140/163]	lr: 5.782e-05, eta: 1:01:33, time: 2.248, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4828, decode.acc_seg: 85.0561, aux.loss_ce: 0.2134, aux.acc_seg: 83.9452, loss: 0.6962, grad_norm: 2.2838
2021-10-25 03:47:36,360 - mmseg - INFO - Epoch [10][150/163]	lr: 5.782e-05, eta: 1:01:11, time: 2.250, data_time: 0.011, memory: 29235, decode.loss_ce: 0.5222, decode.acc_seg: 83.2006, aux.loss_ce: 0.2368, aux.acc_seg: 81.6264, loss: 0.7590, grad_norm: 2.2076
2021-10-25 03:47:58,844 - mmseg - INFO - Epoch [10][160/163]	lr: 5.782e-05, eta: 1:00:49, time: 2.248, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5532, decode.acc_seg: 82.9689, aux.loss_ce: 0.2486, aux.acc_seg: 81.4437, loss: 0.8018, grad_norm: 2.2101
2021-10-25 03:49:00,835 - mmseg - INFO - per class results:
2021-10-25 03:49:00,836 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|   Background  | 87.35 | 97.71 |
| General trash | 21.01 | 31.94 |
|     Paper     | 40.17 | 67.95 |
|   Paper pack  |  0.27 |  0.27 |
|     Metal     |  3.18 |  3.44 |
|     Glass     |  3.55 |  3.95 |
|    Plastic    |  9.39 | 11.35 |
|   Styrofoam   | 23.29 | 29.93 |
|  Plastic bag  | 40.72 | 46.55 |
|    Battery    |  0.0  |  0.0  |
|    Clothing   |  3.15 |  3.37 |
+---------------+-------+-------+
2021-10-25 03:49:00,837 - mmseg - INFO - Summary:
2021-10-25 03:49:00,837 - mmseg - INFO - 
+-------+------+-------+
|  aAcc | mIoU |  mAcc |
+-------+------+-------+
| 81.43 | 21.1 | 26.95 |
+-------+------+-------+
2021-10-25 03:49:00,840 - mmseg - INFO - Exp name: UperCSwinT.py
2021-10-25 03:49:00,840 - mmseg - INFO - Epoch(val) [10][655]	aAcc: 0.8143, mIoU: 0.2110, mAcc: 0.2695, IoU.Background: 0.8735, IoU.General trash: 0.2101, IoU.Paper: 0.4017, IoU.Paper pack: 0.0027, IoU.Metal: 0.0318, IoU.Glass: 0.0355, IoU.Plastic: 0.0939, IoU.Styrofoam: 0.2329, IoU.Plastic bag: 0.4072, IoU.Battery: 0.0000, IoU.Clothing: 0.0315, Acc.Background: 0.9771, Acc.General trash: 0.3194, Acc.Paper: 0.6795, Acc.Paper pack: 0.0027, Acc.Metal: 0.0344, Acc.Glass: 0.0395, Acc.Plastic: 0.1135, Acc.Styrofoam: 0.2993, Acc.Plastic bag: 0.4655, Acc.Battery: 0.0000, Acc.Clothing: 0.0337
2021-10-25 03:49:26,280 - mmseg - INFO - Epoch [11][10/163]	lr: 5.000e-05, eta: 1:00:16, time: 2.542, data_time: 0.289, memory: 29235, decode.loss_ce: 0.5067, decode.acc_seg: 84.1753, aux.loss_ce: 0.2417, aux.acc_seg: 81.4605, loss: 0.7484, grad_norm: 2.1027
2021-10-25 03:49:48,806 - mmseg - INFO - Epoch [11][20/163]	lr: 5.000e-05, eta: 0:59:54, time: 2.253, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5439, decode.acc_seg: 83.1018, aux.loss_ce: 0.2524, aux.acc_seg: 81.3924, loss: 0.7963, grad_norm: 2.2114
2021-10-25 03:50:11,314 - mmseg - INFO - Epoch [11][30/163]	lr: 5.000e-05, eta: 0:59:32, time: 2.251, data_time: 0.011, memory: 29235, decode.loss_ce: 0.5250, decode.acc_seg: 83.4866, aux.loss_ce: 0.2431, aux.acc_seg: 81.4303, loss: 0.7681, grad_norm: 2.1387
2021-10-25 03:50:33,809 - mmseg - INFO - Epoch [11][40/163]	lr: 5.000e-05, eta: 0:59:09, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4920, decode.acc_seg: 84.9523, aux.loss_ce: 0.2253, aux.acc_seg: 83.0795, loss: 0.7173, grad_norm: 2.4205
2021-10-25 03:50:56,323 - mmseg - INFO - Epoch [11][50/163]	lr: 5.000e-05, eta: 0:58:47, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5325, decode.acc_seg: 83.8555, aux.loss_ce: 0.2435, aux.acc_seg: 81.7330, loss: 0.7760, grad_norm: 2.8372
2021-10-25 03:51:18,836 - mmseg - INFO - Epoch [11][60/163]	lr: 5.000e-05, eta: 0:58:25, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5089, decode.acc_seg: 83.4419, aux.loss_ce: 0.2372, aux.acc_seg: 81.7114, loss: 0.7461, grad_norm: 2.1284
2021-10-25 03:51:41,335 - mmseg - INFO - Epoch [11][70/163]	lr: 5.000e-05, eta: 0:58:03, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5216, decode.acc_seg: 82.9017, aux.loss_ce: 0.2431, aux.acc_seg: 80.4021, loss: 0.7647, grad_norm: 2.3962
2021-10-25 03:52:03,847 - mmseg - INFO - Epoch [11][80/163]	lr: 5.000e-05, eta: 0:57:41, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5336, decode.acc_seg: 83.7776, aux.loss_ce: 0.2389, aux.acc_seg: 82.0888, loss: 0.7726, grad_norm: 2.2328
2021-10-25 03:52:26,346 - mmseg - INFO - Epoch [11][90/163]	lr: 5.000e-05, eta: 0:57:19, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5431, decode.acc_seg: 83.2580, aux.loss_ce: 0.2440, aux.acc_seg: 81.9801, loss: 0.7871, grad_norm: 2.4159
2021-10-25 03:52:48,837 - mmseg - INFO - Epoch [11][100/163]	lr: 5.000e-05, eta: 0:56:56, time: 2.249, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5197, decode.acc_seg: 83.5053, aux.loss_ce: 0.2420, aux.acc_seg: 81.3385, loss: 0.7617, grad_norm: 2.3910
2021-10-25 03:53:11,410 - mmseg - INFO - Epoch [11][110/163]	lr: 5.000e-05, eta: 0:56:34, time: 2.257, data_time: 0.011, memory: 29235, decode.loss_ce: 0.5445, decode.acc_seg: 82.5107, aux.loss_ce: 0.2437, aux.acc_seg: 81.4509, loss: 0.7882, grad_norm: 2.5142
2021-10-25 03:53:34,052 - mmseg - INFO - Epoch [11][120/163]	lr: 5.000e-05, eta: 0:56:12, time: 2.264, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5308, decode.acc_seg: 83.3697, aux.loss_ce: 0.2451, aux.acc_seg: 81.9414, loss: 0.7759, grad_norm: 1.9508
2021-10-25 03:53:56,592 - mmseg - INFO - Epoch [11][130/163]	lr: 5.000e-05, eta: 0:55:50, time: 2.254, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4533, decode.acc_seg: 86.1945, aux.loss_ce: 0.2046, aux.acc_seg: 84.8936, loss: 0.6579, grad_norm: 2.0397
2021-10-25 03:54:19,101 - mmseg - INFO - Epoch [11][140/163]	lr: 5.000e-05, eta: 0:55:28, time: 2.251, data_time: 0.011, memory: 29235, decode.loss_ce: 0.5528, decode.acc_seg: 82.1711, aux.loss_ce: 0.2530, aux.acc_seg: 80.8919, loss: 0.8058, grad_norm: 2.5405
2021-10-25 03:54:41,619 - mmseg - INFO - Epoch [11][150/163]	lr: 5.000e-05, eta: 0:55:06, time: 2.252, data_time: 0.011, memory: 29235, decode.loss_ce: 0.5051, decode.acc_seg: 84.3905, aux.loss_ce: 0.2328, aux.acc_seg: 82.2783, loss: 0.7379, grad_norm: 2.2023
2021-10-25 03:55:04,176 - mmseg - INFO - Epoch [11][160/163]	lr: 5.000e-05, eta: 0:54:44, time: 2.256, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5245, decode.acc_seg: 82.9140, aux.loss_ce: 0.2379, aux.acc_seg: 81.5164, loss: 0.7623, grad_norm: 2.4947
2021-10-25 03:56:05,243 - mmseg - INFO - per class results:
2021-10-25 03:56:05,245 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|   Background  | 88.07 |  96.0 |
| General trash | 21.03 | 28.17 |
|     Paper     |  46.6 | 69.19 |
|   Paper pack  |  6.85 |  8.59 |
|     Metal     |  3.28 |  4.28 |
|     Glass     |  8.96 |  12.1 |
|    Plastic    | 12.09 | 15.49 |
|   Styrofoam   | 26.77 | 37.33 |
|  Plastic bag  | 53.96 | 68.41 |
|    Battery    |  0.0  |  0.0  |
|    Clothing   |  5.93 |  7.22 |
+---------------+-------+-------+
2021-10-25 03:56:05,245 - mmseg - INFO - Summary:
2021-10-25 03:56:05,245 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 83.21 | 24.87 | 31.52 |
+-------+-------+-------+
2021-10-25 03:56:06,809 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_epoch_11.pth.
2021-10-25 03:56:06,809 - mmseg - INFO - Best mIoU is 0.2487 at 11 epoch.
2021-10-25 03:56:06,813 - mmseg - INFO - Exp name: UperCSwinT.py
2021-10-25 03:56:06,813 - mmseg - INFO - Epoch(val) [11][655]	aAcc: 0.8321, mIoU: 0.2487, mAcc: 0.3152, IoU.Background: 0.8807, IoU.General trash: 0.2103, IoU.Paper: 0.4660, IoU.Paper pack: 0.0685, IoU.Metal: 0.0328, IoU.Glass: 0.0896, IoU.Plastic: 0.1209, IoU.Styrofoam: 0.2677, IoU.Plastic bag: 0.5396, IoU.Battery: 0.0000, IoU.Clothing: 0.0593, Acc.Background: 0.9600, Acc.General trash: 0.2817, Acc.Paper: 0.6919, Acc.Paper pack: 0.0859, Acc.Metal: 0.0428, Acc.Glass: 0.1210, Acc.Plastic: 0.1549, Acc.Styrofoam: 0.3733, Acc.Plastic bag: 0.6841, Acc.Battery: 0.0000, Acc.Clothing: 0.0722
2021-10-25 03:56:32,470 - mmseg - INFO - Epoch [12][10/163]	lr: 4.218e-05, eta: 0:54:12, time: 2.564, data_time: 0.307, memory: 29235, decode.loss_ce: 0.5171, decode.acc_seg: 83.4850, aux.loss_ce: 0.2390, aux.acc_seg: 81.2441, loss: 0.7561, grad_norm: 1.9162
2021-10-25 03:56:55,033 - mmseg - INFO - Epoch [12][20/163]	lr: 4.218e-05, eta: 0:53:50, time: 2.256, data_time: 0.011, memory: 29235, decode.loss_ce: 0.5096, decode.acc_seg: 83.5249, aux.loss_ce: 0.2322, aux.acc_seg: 81.8793, loss: 0.7418, grad_norm: 2.1927
2021-10-25 03:57:17,548 - mmseg - INFO - Epoch [12][30/163]	lr: 4.218e-05, eta: 0:53:27, time: 2.252, data_time: 0.011, memory: 29235, decode.loss_ce: 0.4476, decode.acc_seg: 86.1271, aux.loss_ce: 0.2067, aux.acc_seg: 84.3969, loss: 0.6543, grad_norm: 2.2167
2021-10-25 03:57:40,032 - mmseg - INFO - Epoch [12][40/163]	lr: 4.218e-05, eta: 0:53:05, time: 2.248, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5053, decode.acc_seg: 83.7192, aux.loss_ce: 0.2326, aux.acc_seg: 82.6071, loss: 0.7380, grad_norm: 2.0980
2021-10-25 03:58:02,548 - mmseg - INFO - Epoch [12][50/163]	lr: 4.218e-05, eta: 0:52:43, time: 2.252, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4979, decode.acc_seg: 84.6484, aux.loss_ce: 0.2344, aux.acc_seg: 81.8841, loss: 0.7324, grad_norm: 2.1084
2021-10-25 03:58:25,070 - mmseg - INFO - Epoch [12][60/163]	lr: 4.218e-05, eta: 0:52:21, time: 2.252, data_time: 0.011, memory: 29235, decode.loss_ce: 0.5010, decode.acc_seg: 84.0496, aux.loss_ce: 0.2326, aux.acc_seg: 82.1190, loss: 0.7336, grad_norm: 1.8593
2021-10-25 03:58:47,584 - mmseg - INFO - Epoch [12][70/163]	lr: 4.218e-05, eta: 0:51:59, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5259, decode.acc_seg: 83.4835, aux.loss_ce: 0.2433, aux.acc_seg: 81.1436, loss: 0.7692, grad_norm: 2.4528
2021-10-25 03:59:10,092 - mmseg - INFO - Epoch [12][80/163]	lr: 4.218e-05, eta: 0:51:37, time: 2.251, data_time: 0.011, memory: 29235, decode.loss_ce: 0.4495, decode.acc_seg: 85.6430, aux.loss_ce: 0.2119, aux.acc_seg: 84.0466, loss: 0.6614, grad_norm: 2.6197
2021-10-25 03:59:32,587 - mmseg - INFO - Epoch [12][90/163]	lr: 4.218e-05, eta: 0:51:14, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4922, decode.acc_seg: 84.0165, aux.loss_ce: 0.2276, aux.acc_seg: 83.0951, loss: 0.7198, grad_norm: 2.3488
2021-10-25 03:59:55,130 - mmseg - INFO - Epoch [12][100/163]	lr: 4.218e-05, eta: 0:50:52, time: 2.254, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5119, decode.acc_seg: 83.9416, aux.loss_ce: 0.2370, aux.acc_seg: 82.1605, loss: 0.7489, grad_norm: 2.6744
2021-10-25 04:00:17,714 - mmseg - INFO - Epoch [12][110/163]	lr: 4.218e-05, eta: 0:50:30, time: 2.258, data_time: 0.012, memory: 29235, decode.loss_ce: 0.5580, decode.acc_seg: 82.8510, aux.loss_ce: 0.2552, aux.acc_seg: 80.9492, loss: 0.8132, grad_norm: 2.5117
2021-10-25 04:00:40,295 - mmseg - INFO - Epoch [12][120/163]	lr: 4.218e-05, eta: 0:50:08, time: 2.258, data_time: 0.011, memory: 29235, decode.loss_ce: 0.5327, decode.acc_seg: 83.6028, aux.loss_ce: 0.2420, aux.acc_seg: 82.0291, loss: 0.7748, grad_norm: 2.3093
2021-10-25 04:01:02,836 - mmseg - INFO - Epoch [12][130/163]	lr: 4.218e-05, eta: 0:49:46, time: 2.254, data_time: 0.011, memory: 29235, decode.loss_ce: 0.5041, decode.acc_seg: 83.8942, aux.loss_ce: 0.2285, aux.acc_seg: 82.6437, loss: 0.7326, grad_norm: 2.0774
2021-10-25 04:01:25,339 - mmseg - INFO - Epoch [12][140/163]	lr: 4.218e-05, eta: 0:49:23, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5990, decode.acc_seg: 81.2640, aux.loss_ce: 0.2684, aux.acc_seg: 79.5405, loss: 0.8674, grad_norm: 2.4652
2021-10-25 04:01:47,840 - mmseg - INFO - Epoch [12][150/163]	lr: 4.218e-05, eta: 0:49:01, time: 2.250, data_time: 0.011, memory: 29235, decode.loss_ce: 0.4599, decode.acc_seg: 85.4867, aux.loss_ce: 0.2156, aux.acc_seg: 83.6823, loss: 0.6755, grad_norm: 2.0905
2021-10-25 04:02:10,310 - mmseg - INFO - Epoch [12][160/163]	lr: 4.218e-05, eta: 0:48:39, time: 2.247, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5020, decode.acc_seg: 84.1649, aux.loss_ce: 0.2335, aux.acc_seg: 82.3411, loss: 0.7355, grad_norm: 2.4793
2021-10-25 04:03:13,725 - mmseg - INFO - per class results:
2021-10-25 04:03:13,726 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|   Background  | 88.43 | 96.28 |
| General trash | 21.29 | 28.49 |
|     Paper     | 48.12 | 68.58 |
|   Paper pack  |  5.28 |  5.85 |
|     Metal     |  4.73 |  5.46 |
|     Glass     |  4.27 |  4.69 |
|    Plastic    | 13.29 | 17.95 |
|   Styrofoam   | 29.18 | 44.74 |
|  Plastic bag  | 53.27 | 69.65 |
|    Battery    |  0.0  |  0.0  |
|    Clothing   |  2.4  |  2.54 |
+---------------+-------+-------+
2021-10-25 04:03:13,726 - mmseg - INFO - Summary:
2021-10-25 04:03:13,727 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 83.57 | 24.57 | 31.29 |
+-------+-------+-------+
2021-10-25 04:03:13,730 - mmseg - INFO - Exp name: UperCSwinT.py
2021-10-25 04:03:13,730 - mmseg - INFO - Epoch(val) [12][655]	aAcc: 0.8357, mIoU: 0.2457, mAcc: 0.3129, IoU.Background: 0.8843, IoU.General trash: 0.2129, IoU.Paper: 0.4812, IoU.Paper pack: 0.0528, IoU.Metal: 0.0473, IoU.Glass: 0.0427, IoU.Plastic: 0.1329, IoU.Styrofoam: 0.2918, IoU.Plastic bag: 0.5327, IoU.Battery: 0.0000, IoU.Clothing: 0.0240, Acc.Background: 0.9628, Acc.General trash: 0.2849, Acc.Paper: 0.6858, Acc.Paper pack: 0.0585, Acc.Metal: 0.0546, Acc.Glass: 0.0469, Acc.Plastic: 0.1795, Acc.Styrofoam: 0.4474, Acc.Plastic bag: 0.6965, Acc.Battery: 0.0000, Acc.Clothing: 0.0254
2021-10-25 04:03:39,242 - mmseg - INFO - Epoch [13][10/163]	lr: 3.455e-05, eta: 0:48:08, time: 2.550, data_time: 0.299, memory: 29235, decode.loss_ce: 0.4525, decode.acc_seg: 86.3821, aux.loss_ce: 0.2128, aux.acc_seg: 84.6286, loss: 0.6653, grad_norm: 2.0093
2021-10-25 04:04:01,759 - mmseg - INFO - Epoch [13][20/163]	lr: 3.455e-05, eta: 0:47:45, time: 2.252, data_time: 0.012, memory: 29235, decode.loss_ce: 0.4156, decode.acc_seg: 86.7993, aux.loss_ce: 0.2066, aux.acc_seg: 84.1496, loss: 0.6222, grad_norm: 2.2459
2021-10-25 04:04:24,299 - mmseg - INFO - Epoch [13][30/163]	lr: 3.455e-05, eta: 0:47:23, time: 2.254, data_time: 0.011, memory: 29235, decode.loss_ce: 0.4799, decode.acc_seg: 84.8314, aux.loss_ce: 0.2209, aux.acc_seg: 83.3143, loss: 0.7008, grad_norm: 2.1605
2021-10-25 04:04:46,827 - mmseg - INFO - Epoch [13][40/163]	lr: 3.455e-05, eta: 0:47:01, time: 2.253, data_time: 0.011, memory: 29235, decode.loss_ce: 0.4784, decode.acc_seg: 84.6708, aux.loss_ce: 0.2257, aux.acc_seg: 82.3723, loss: 0.7041, grad_norm: 2.3091
2021-10-25 04:05:09,435 - mmseg - INFO - Epoch [13][50/163]	lr: 3.455e-05, eta: 0:46:39, time: 2.261, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4764, decode.acc_seg: 84.9466, aux.loss_ce: 0.2263, aux.acc_seg: 82.3640, loss: 0.7027, grad_norm: 2.1744
2021-10-25 04:05:31,940 - mmseg - INFO - Epoch [13][60/163]	lr: 3.455e-05, eta: 0:46:17, time: 2.251, data_time: 0.011, memory: 29235, decode.loss_ce: 0.4736, decode.acc_seg: 84.2162, aux.loss_ce: 0.2254, aux.acc_seg: 82.3588, loss: 0.6990, grad_norm: 2.2609
2021-10-25 04:05:54,529 - mmseg - INFO - Epoch [13][70/163]	lr: 3.455e-05, eta: 0:45:55, time: 2.259, data_time: 0.011, memory: 29235, decode.loss_ce: 0.5226, decode.acc_seg: 83.3429, aux.loss_ce: 0.2503, aux.acc_seg: 81.2836, loss: 0.7729, grad_norm: 2.5058
2021-10-25 04:06:17,026 - mmseg - INFO - Epoch [13][80/163]	lr: 3.455e-05, eta: 0:45:32, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5763, decode.acc_seg: 82.3988, aux.loss_ce: 0.2700, aux.acc_seg: 80.4909, loss: 0.8463, grad_norm: 2.8232
2021-10-25 04:06:39,533 - mmseg - INFO - Epoch [13][90/163]	lr: 3.455e-05, eta: 0:45:10, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4636, decode.acc_seg: 85.4144, aux.loss_ce: 0.2182, aux.acc_seg: 83.4348, loss: 0.6819, grad_norm: 2.2266
2021-10-25 04:07:02,037 - mmseg - INFO - Epoch [13][100/163]	lr: 3.455e-05, eta: 0:44:48, time: 2.250, data_time: 0.011, memory: 29235, decode.loss_ce: 0.5562, decode.acc_seg: 82.1717, aux.loss_ce: 0.2550, aux.acc_seg: 80.4837, loss: 0.8112, grad_norm: 2.3224
2021-10-25 04:07:24,552 - mmseg - INFO - Epoch [13][110/163]	lr: 3.455e-05, eta: 0:44:26, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5084, decode.acc_seg: 84.1896, aux.loss_ce: 0.2382, aux.acc_seg: 82.3662, loss: 0.7466, grad_norm: 2.4996
2021-10-25 04:07:47,050 - mmseg - INFO - Epoch [13][120/163]	lr: 3.455e-05, eta: 0:44:03, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4984, decode.acc_seg: 84.2918, aux.loss_ce: 0.2283, aux.acc_seg: 82.8707, loss: 0.7267, grad_norm: 2.3927
2021-10-25 04:08:09,639 - mmseg - INFO - Epoch [13][130/163]	lr: 3.455e-05, eta: 0:43:41, time: 2.259, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4712, decode.acc_seg: 84.9131, aux.loss_ce: 0.2288, aux.acc_seg: 82.4497, loss: 0.7000, grad_norm: 2.4657
2021-10-25 04:08:32,157 - mmseg - INFO - Epoch [13][140/163]	lr: 3.455e-05, eta: 0:43:19, time: 2.252, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4266, decode.acc_seg: 86.4509, aux.loss_ce: 0.1986, aux.acc_seg: 84.9298, loss: 0.6252, grad_norm: 2.3402
2021-10-25 04:08:54,732 - mmseg - INFO - Epoch [13][150/163]	lr: 3.455e-05, eta: 0:42:57, time: 2.257, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4909, decode.acc_seg: 84.8829, aux.loss_ce: 0.2312, aux.acc_seg: 82.8481, loss: 0.7221, grad_norm: 2.4054
2021-10-25 04:09:17,230 - mmseg - INFO - Epoch [13][160/163]	lr: 3.455e-05, eta: 0:42:35, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4753, decode.acc_seg: 85.0510, aux.loss_ce: 0.2268, aux.acc_seg: 82.7870, loss: 0.7020, grad_norm: 2.2300
2021-10-25 04:10:18,717 - mmseg - INFO - per class results:
2021-10-25 04:10:18,720 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|   Background  | 87.85 | 97.15 |
| General trash | 23.49 |  30.9 |
|     Paper     | 47.28 | 62.34 |
|   Paper pack  |  4.09 |  4.62 |
|     Metal     |  5.5  |  7.0  |
|     Glass     |  8.45 | 11.88 |
|    Plastic    | 10.76 | 12.47 |
|   Styrofoam   | 28.98 | 42.25 |
|  Plastic bag  | 55.76 | 71.81 |
|    Battery    |  0.0  |  0.0  |
|    Clothing   |  4.63 |  4.88 |
+---------------+-------+-------+
2021-10-25 04:10:18,720 - mmseg - INFO - Summary:
2021-10-25 04:10:18,720 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 83.82 | 25.16 | 31.39 |
+-------+-------+-------+
2021-10-25 04:10:20,273 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_epoch_13.pth.
2021-10-25 04:10:20,273 - mmseg - INFO - Best mIoU is 0.2516 at 13 epoch.
2021-10-25 04:10:20,277 - mmseg - INFO - Exp name: UperCSwinT.py
2021-10-25 04:10:20,277 - mmseg - INFO - Epoch(val) [13][655]	aAcc: 0.8382, mIoU: 0.2516, mAcc: 0.3139, IoU.Background: 0.8785, IoU.General trash: 0.2349, IoU.Paper: 0.4728, IoU.Paper pack: 0.0409, IoU.Metal: 0.0550, IoU.Glass: 0.0845, IoU.Plastic: 0.1076, IoU.Styrofoam: 0.2898, IoU.Plastic bag: 0.5576, IoU.Battery: 0.0000, IoU.Clothing: 0.0463, Acc.Background: 0.9715, Acc.General trash: 0.3090, Acc.Paper: 0.6234, Acc.Paper pack: 0.0462, Acc.Metal: 0.0700, Acc.Glass: 0.1188, Acc.Plastic: 0.1247, Acc.Styrofoam: 0.4225, Acc.Plastic bag: 0.7181, Acc.Battery: 0.0000, Acc.Clothing: 0.0488
2021-10-25 04:10:45,991 - mmseg - INFO - Epoch [14][10/163]	lr: 2.730e-05, eta: 0:42:04, time: 2.570, data_time: 0.322, memory: 29235, decode.loss_ce: 0.4548, decode.acc_seg: 86.4461, aux.loss_ce: 0.2137, aux.acc_seg: 83.5991, loss: 0.6686, grad_norm: 2.1475
2021-10-25 04:11:08,632 - mmseg - INFO - Epoch [14][20/163]	lr: 2.730e-05, eta: 0:41:42, time: 2.264, data_time: 0.012, memory: 29235, decode.loss_ce: 0.4535, decode.acc_seg: 84.9149, aux.loss_ce: 0.2224, aux.acc_seg: 82.9008, loss: 0.6759, grad_norm: 2.5112
2021-10-25 04:11:31,153 - mmseg - INFO - Epoch [14][30/163]	lr: 2.730e-05, eta: 0:41:19, time: 2.252, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4151, decode.acc_seg: 87.0040, aux.loss_ce: 0.2009, aux.acc_seg: 84.9301, loss: 0.6160, grad_norm: 2.5186
2021-10-25 04:11:53,670 - mmseg - INFO - Epoch [14][40/163]	lr: 2.730e-05, eta: 0:40:57, time: 2.252, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5053, decode.acc_seg: 83.4892, aux.loss_ce: 0.2515, aux.acc_seg: 80.2947, loss: 0.7567, grad_norm: 2.7854
2021-10-25 04:12:16,190 - mmseg - INFO - Epoch [14][50/163]	lr: 2.730e-05, eta: 0:40:35, time: 2.252, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4720, decode.acc_seg: 85.3375, aux.loss_ce: 0.2194, aux.acc_seg: 83.8216, loss: 0.6914, grad_norm: 2.1523
2021-10-25 04:12:38,729 - mmseg - INFO - Epoch [14][60/163]	lr: 2.730e-05, eta: 0:40:13, time: 2.254, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5125, decode.acc_seg: 84.2862, aux.loss_ce: 0.2449, aux.acc_seg: 81.9760, loss: 0.7574, grad_norm: 2.3496
2021-10-25 04:13:01,240 - mmseg - INFO - Epoch [14][70/163]	lr: 2.730e-05, eta: 0:39:50, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4544, decode.acc_seg: 85.5418, aux.loss_ce: 0.2185, aux.acc_seg: 82.7967, loss: 0.6730, grad_norm: 2.2820
2021-10-25 04:13:23,736 - mmseg - INFO - Epoch [14][80/163]	lr: 2.730e-05, eta: 0:39:28, time: 2.250, data_time: 0.011, memory: 29235, decode.loss_ce: 0.4388, decode.acc_seg: 85.9708, aux.loss_ce: 0.2172, aux.acc_seg: 83.0330, loss: 0.6560, grad_norm: 2.1223
2021-10-25 04:13:46,244 - mmseg - INFO - Epoch [14][90/163]	lr: 2.730e-05, eta: 0:39:06, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4298, decode.acc_seg: 86.3360, aux.loss_ce: 0.2097, aux.acc_seg: 84.3255, loss: 0.6395, grad_norm: 1.9498
2021-10-25 04:14:08,770 - mmseg - INFO - Epoch [14][100/163]	lr: 2.730e-05, eta: 0:38:44, time: 2.253, data_time: 0.011, memory: 29235, decode.loss_ce: 0.4926, decode.acc_seg: 84.8592, aux.loss_ce: 0.2327, aux.acc_seg: 82.6085, loss: 0.7253, grad_norm: 2.2602
2021-10-25 04:14:31,302 - mmseg - INFO - Epoch [14][110/163]	lr: 2.730e-05, eta: 0:38:22, time: 2.253, data_time: 0.011, memory: 29235, decode.loss_ce: 0.4845, decode.acc_seg: 84.6604, aux.loss_ce: 0.2276, aux.acc_seg: 82.1395, loss: 0.7121, grad_norm: 2.6116
2021-10-25 04:14:53,866 - mmseg - INFO - Epoch [14][120/163]	lr: 2.730e-05, eta: 0:37:59, time: 2.256, data_time: 0.011, memory: 29235, decode.loss_ce: 0.4424, decode.acc_seg: 86.4796, aux.loss_ce: 0.2051, aux.acc_seg: 84.9025, loss: 0.6476, grad_norm: 2.3920
2021-10-25 04:15:16,390 - mmseg - INFO - Epoch [14][130/163]	lr: 2.730e-05, eta: 0:37:37, time: 2.252, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4578, decode.acc_seg: 85.8246, aux.loss_ce: 0.2197, aux.acc_seg: 83.4284, loss: 0.6775, grad_norm: 2.7250
2021-10-25 04:15:38,901 - mmseg - INFO - Epoch [14][140/163]	lr: 2.730e-05, eta: 0:37:15, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.5024, decode.acc_seg: 83.9669, aux.loss_ce: 0.2392, aux.acc_seg: 81.7114, loss: 0.7416, grad_norm: 2.3086
2021-10-25 04:16:01,402 - mmseg - INFO - Epoch [14][150/163]	lr: 2.730e-05, eta: 0:36:53, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4621, decode.acc_seg: 85.2242, aux.loss_ce: 0.2200, aux.acc_seg: 83.1964, loss: 0.6821, grad_norm: 2.4802
2021-10-25 04:16:23,903 - mmseg - INFO - Epoch [14][160/163]	lr: 2.730e-05, eta: 0:36:30, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4850, decode.acc_seg: 84.6337, aux.loss_ce: 0.2322, aux.acc_seg: 82.3042, loss: 0.7172, grad_norm: 2.3931
2021-10-25 04:17:25,785 - mmseg - INFO - per class results:
2021-10-25 04:17:25,786 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|   Background  | 88.62 | 97.06 |
| General trash | 24.17 | 36.34 |
|     Paper     | 49.55 | 58.38 |
|   Paper pack  |  7.68 |  8.39 |
|     Metal     |  9.31 | 12.01 |
|     Glass     | 13.28 | 24.73 |
|    Plastic    | 14.96 | 21.48 |
|   Styrofoam   | 27.74 | 37.05 |
|  Plastic bag  | 56.35 | 74.19 |
|    Battery    |  0.0  |  0.0  |
|    Clothing   |  11.2 | 12.94 |
+---------------+-------+-------+
2021-10-25 04:17:25,786 - mmseg - INFO - Summary:
2021-10-25 04:17:25,786 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 84.16 | 27.53 | 34.78 |
+-------+-------+-------+
2021-10-25 04:17:27,491 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_epoch_14.pth.
2021-10-25 04:17:27,491 - mmseg - INFO - Best mIoU is 0.2753 at 14 epoch.
2021-10-25 04:17:27,494 - mmseg - INFO - Exp name: UperCSwinT.py
2021-10-25 04:17:27,495 - mmseg - INFO - Epoch(val) [14][655]	aAcc: 0.8416, mIoU: 0.2753, mAcc: 0.3478, IoU.Background: 0.8862, IoU.General trash: 0.2417, IoU.Paper: 0.4955, IoU.Paper pack: 0.0768, IoU.Metal: 0.0931, IoU.Glass: 0.1328, IoU.Plastic: 0.1496, IoU.Styrofoam: 0.2774, IoU.Plastic bag: 0.5635, IoU.Battery: 0.0000, IoU.Clothing: 0.1120, Acc.Background: 0.9706, Acc.General trash: 0.3634, Acc.Paper: 0.5838, Acc.Paper pack: 0.0839, Acc.Metal: 0.1201, Acc.Glass: 0.2473, Acc.Plastic: 0.2148, Acc.Styrofoam: 0.3705, Acc.Plastic bag: 0.7419, Acc.Battery: 0.0000, Acc.Clothing: 0.1294
2021-10-25 04:17:53,273 - mmseg - INFO - Epoch [15][10/163]	lr: 2.061e-05, eta: 0:36:00, time: 2.576, data_time: 0.330, memory: 29235, decode.loss_ce: 0.4432, decode.acc_seg: 86.2348, aux.loss_ce: 0.2119, aux.acc_seg: 84.0489, loss: 0.6551, grad_norm: 2.1476
2021-10-25 04:18:15,856 - mmseg - INFO - Epoch [15][20/163]	lr: 2.061e-05, eta: 0:35:38, time: 2.258, data_time: 0.011, memory: 29235, decode.loss_ce: 0.4462, decode.acc_seg: 85.9905, aux.loss_ce: 0.2176, aux.acc_seg: 82.7728, loss: 0.6638, grad_norm: 2.3663
2021-10-25 04:18:38,401 - mmseg - INFO - Epoch [15][30/163]	lr: 2.061e-05, eta: 0:35:15, time: 2.255, data_time: 0.010, memory: 29235, decode.loss_ce: 0.3982, decode.acc_seg: 87.6344, aux.loss_ce: 0.2001, aux.acc_seg: 84.9460, loss: 0.5982, grad_norm: 1.9818
2021-10-25 04:19:00,943 - mmseg - INFO - Epoch [15][40/163]	lr: 2.061e-05, eta: 0:34:53, time: 2.254, data_time: 0.012, memory: 29235, decode.loss_ce: 0.4683, decode.acc_seg: 85.4814, aux.loss_ce: 0.2211, aux.acc_seg: 83.3000, loss: 0.6894, grad_norm: 2.0674
2021-10-25 04:19:23,450 - mmseg - INFO - Epoch [15][50/163]	lr: 2.061e-05, eta: 0:34:31, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4499, decode.acc_seg: 85.1214, aux.loss_ce: 0.2127, aux.acc_seg: 82.8033, loss: 0.6626, grad_norm: 2.3829
2021-10-25 04:19:45,955 - mmseg - INFO - Epoch [15][60/163]	lr: 2.061e-05, eta: 0:34:09, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4454, decode.acc_seg: 85.7860, aux.loss_ce: 0.2108, aux.acc_seg: 83.7280, loss: 0.6562, grad_norm: 2.2500
2021-10-25 04:20:08,554 - mmseg - INFO - Epoch [15][70/163]	lr: 2.061e-05, eta: 0:33:47, time: 2.260, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4230, decode.acc_seg: 86.7957, aux.loss_ce: 0.2164, aux.acc_seg: 83.5016, loss: 0.6394, grad_norm: 2.5398
2021-10-25 04:20:31,055 - mmseg - INFO - Epoch [15][80/163]	lr: 2.061e-05, eta: 0:33:24, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4464, decode.acc_seg: 86.0672, aux.loss_ce: 0.2127, aux.acc_seg: 84.3611, loss: 0.6591, grad_norm: 2.6349
2021-10-25 04:20:53,560 - mmseg - INFO - Epoch [15][90/163]	lr: 2.061e-05, eta: 0:33:02, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4738, decode.acc_seg: 85.1294, aux.loss_ce: 0.2357, aux.acc_seg: 81.5982, loss: 0.7095, grad_norm: 2.1543
2021-10-25 04:21:16,070 - mmseg - INFO - Epoch [15][100/163]	lr: 2.061e-05, eta: 0:32:40, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4469, decode.acc_seg: 85.9920, aux.loss_ce: 0.2183, aux.acc_seg: 83.3482, loss: 0.6652, grad_norm: 2.4686
2021-10-25 04:21:38,583 - mmseg - INFO - Epoch [15][110/163]	lr: 2.061e-05, eta: 0:32:17, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4163, decode.acc_seg: 87.0329, aux.loss_ce: 0.2013, aux.acc_seg: 84.4671, loss: 0.6175, grad_norm: 2.2020
2021-10-25 04:22:01,078 - mmseg - INFO - Epoch [15][120/163]	lr: 2.061e-05, eta: 0:31:55, time: 2.249, data_time: 0.011, memory: 29235, decode.loss_ce: 0.4651, decode.acc_seg: 85.5953, aux.loss_ce: 0.2236, aux.acc_seg: 83.1373, loss: 0.6887, grad_norm: 2.8921
2021-10-25 04:22:23,582 - mmseg - INFO - Epoch [15][130/163]	lr: 2.061e-05, eta: 0:31:33, time: 2.250, data_time: 0.011, memory: 29235, decode.loss_ce: 0.5350, decode.acc_seg: 82.9787, aux.loss_ce: 0.2641, aux.acc_seg: 79.4542, loss: 0.7991, grad_norm: 3.0917
2021-10-25 04:22:46,116 - mmseg - INFO - Epoch [15][140/163]	lr: 2.061e-05, eta: 0:31:11, time: 2.253, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4726, decode.acc_seg: 84.8333, aux.loss_ce: 0.2270, aux.acc_seg: 82.7452, loss: 0.6996, grad_norm: 2.2555
2021-10-25 04:23:08,615 - mmseg - INFO - Epoch [15][150/163]	lr: 2.061e-05, eta: 0:30:48, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4657, decode.acc_seg: 85.6586, aux.loss_ce: 0.2267, aux.acc_seg: 82.9549, loss: 0.6924, grad_norm: 2.3958
2021-10-25 04:23:31,085 - mmseg - INFO - Epoch [15][160/163]	lr: 2.061e-05, eta: 0:30:26, time: 2.247, data_time: 0.010, memory: 29235, decode.loss_ce: 0.3656, decode.acc_seg: 88.9433, aux.loss_ce: 0.1812, aux.acc_seg: 86.3507, loss: 0.5468, grad_norm: 2.1644
2021-10-25 04:24:33,809 - mmseg - INFO - per class results:
2021-10-25 04:24:33,810 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|   Background  | 88.63 | 97.31 |
| General trash | 18.65 | 24.58 |
|     Paper     | 47.89 | 70.63 |
|   Paper pack  |  5.11 |  6.21 |
|     Metal     |  5.61 |  6.96 |
|     Glass     | 16.17 | 26.49 |
|    Plastic    | 11.19 | 13.27 |
|   Styrofoam   | 26.94 | 37.29 |
|  Plastic bag  | 54.52 | 65.02 |
|    Battery    |  0.0  |  0.0  |
|    Clothing   |  5.52 |  5.72 |
+---------------+-------+-------+
2021-10-25 04:24:33,810 - mmseg - INFO - Summary:
2021-10-25 04:24:33,810 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 83.86 | 25.48 | 32.14 |
+-------+-------+-------+
2021-10-25 04:24:33,813 - mmseg - INFO - Exp name: UperCSwinT.py
2021-10-25 04:24:33,814 - mmseg - INFO - Epoch(val) [15][655]	aAcc: 0.8386, mIoU: 0.2548, mAcc: 0.3214, IoU.Background: 0.8863, IoU.General trash: 0.1865, IoU.Paper: 0.4789, IoU.Paper pack: 0.0511, IoU.Metal: 0.0561, IoU.Glass: 0.1617, IoU.Plastic: 0.1119, IoU.Styrofoam: 0.2694, IoU.Plastic bag: 0.5452, IoU.Battery: 0.0000, IoU.Clothing: 0.0552, Acc.Background: 0.9731, Acc.General trash: 0.2458, Acc.Paper: 0.7063, Acc.Paper pack: 0.0621, Acc.Metal: 0.0696, Acc.Glass: 0.2649, Acc.Plastic: 0.1327, Acc.Styrofoam: 0.3729, Acc.Plastic bag: 0.6502, Acc.Battery: 0.0000, Acc.Clothing: 0.0572
2021-10-25 04:24:59,276 - mmseg - INFO - Epoch [16][10/163]	lr: 1.465e-05, eta: 0:29:56, time: 2.545, data_time: 0.299, memory: 29235, decode.loss_ce: 0.4490, decode.acc_seg: 86.1060, aux.loss_ce: 0.2193, aux.acc_seg: 83.0826, loss: 0.6682, grad_norm: 2.3454
2021-10-25 04:25:21,800 - mmseg - INFO - Epoch [16][20/163]	lr: 1.465e-05, eta: 0:29:34, time: 2.252, data_time: 0.011, memory: 29235, decode.loss_ce: 0.4015, decode.acc_seg: 87.6909, aux.loss_ce: 0.2023, aux.acc_seg: 84.9869, loss: 0.6037, grad_norm: 1.9104
2021-10-25 04:25:44,355 - mmseg - INFO - Epoch [16][30/163]	lr: 1.465e-05, eta: 0:29:11, time: 2.255, data_time: 0.011, memory: 29235, decode.loss_ce: 0.4039, decode.acc_seg: 87.0792, aux.loss_ce: 0.1981, aux.acc_seg: 84.9038, loss: 0.6020, grad_norm: 2.4518
2021-10-25 04:26:06,870 - mmseg - INFO - Epoch [16][40/163]	lr: 1.465e-05, eta: 0:28:49, time: 2.252, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4132, decode.acc_seg: 87.3544, aux.loss_ce: 0.2003, aux.acc_seg: 85.1243, loss: 0.6134, grad_norm: 2.1184
2021-10-25 04:26:29,391 - mmseg - INFO - Epoch [16][50/163]	lr: 1.465e-05, eta: 0:28:27, time: 2.252, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4392, decode.acc_seg: 85.8363, aux.loss_ce: 0.2154, aux.acc_seg: 83.3038, loss: 0.6546, grad_norm: 2.3389
2021-10-25 04:26:51,943 - mmseg - INFO - Epoch [16][60/163]	lr: 1.465e-05, eta: 0:28:05, time: 2.255, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4631, decode.acc_seg: 85.3295, aux.loss_ce: 0.2329, aux.acc_seg: 81.5890, loss: 0.6960, grad_norm: 2.3139
2021-10-25 04:27:14,448 - mmseg - INFO - Epoch [16][70/163]	lr: 1.465e-05, eta: 0:27:42, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4563, decode.acc_seg: 85.6246, aux.loss_ce: 0.2265, aux.acc_seg: 83.1068, loss: 0.6828, grad_norm: 2.2150
2021-10-25 04:27:36,998 - mmseg - INFO - Epoch [16][80/163]	lr: 1.465e-05, eta: 0:27:20, time: 2.255, data_time: 0.011, memory: 29235, decode.loss_ce: 0.4104, decode.acc_seg: 87.3728, aux.loss_ce: 0.2064, aux.acc_seg: 84.1674, loss: 0.6168, grad_norm: 2.3231
2021-10-25 04:27:59,507 - mmseg - INFO - Epoch [16][90/163]	lr: 1.465e-05, eta: 0:26:58, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4525, decode.acc_seg: 86.4448, aux.loss_ce: 0.2236, aux.acc_seg: 83.4405, loss: 0.6760, grad_norm: 2.2523
2021-10-25 04:28:22,009 - mmseg - INFO - Epoch [16][100/163]	lr: 1.465e-05, eta: 0:26:36, time: 2.250, data_time: 0.011, memory: 29235, decode.loss_ce: 0.4067, decode.acc_seg: 87.3025, aux.loss_ce: 0.2049, aux.acc_seg: 84.3416, loss: 0.6116, grad_norm: 2.2460
2021-10-25 04:28:44,506 - mmseg - INFO - Epoch [16][110/163]	lr: 1.465e-05, eta: 0:26:13, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.3894, decode.acc_seg: 87.6631, aux.loss_ce: 0.1916, aux.acc_seg: 85.2216, loss: 0.5810, grad_norm: 2.2818
2021-10-25 04:29:06,995 - mmseg - INFO - Epoch [16][120/163]	lr: 1.465e-05, eta: 0:25:51, time: 2.249, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4803, decode.acc_seg: 84.5820, aux.loss_ce: 0.2346, aux.acc_seg: 81.8117, loss: 0.7149, grad_norm: 2.8490
2021-10-25 04:29:29,527 - mmseg - INFO - Epoch [16][130/163]	lr: 1.465e-05, eta: 0:25:29, time: 2.253, data_time: 0.011, memory: 29235, decode.loss_ce: 0.4646, decode.acc_seg: 85.2278, aux.loss_ce: 0.2296, aux.acc_seg: 82.4440, loss: 0.6942, grad_norm: 2.5953
2021-10-25 04:29:52,030 - mmseg - INFO - Epoch [16][140/163]	lr: 1.465e-05, eta: 0:25:07, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4725, decode.acc_seg: 84.6286, aux.loss_ce: 0.2352, aux.acc_seg: 81.6791, loss: 0.7078, grad_norm: 2.4110
2021-10-25 04:30:14,528 - mmseg - INFO - Epoch [16][150/163]	lr: 1.465e-05, eta: 0:24:44, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.3821, decode.acc_seg: 88.1680, aux.loss_ce: 0.1970, aux.acc_seg: 85.3540, loss: 0.5791, grad_norm: 2.2102
2021-10-25 04:30:36,998 - mmseg - INFO - Epoch [16][160/163]	lr: 1.465e-05, eta: 0:24:22, time: 2.247, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4074, decode.acc_seg: 87.1628, aux.loss_ce: 0.2027, aux.acc_seg: 84.5543, loss: 0.6101, grad_norm: 2.3793
2021-10-25 04:31:39,415 - mmseg - INFO - per class results:
2021-10-25 04:31:39,416 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|   Background  | 88.98 | 96.15 |
| General trash | 22.84 | 29.58 |
|     Paper     | 50.42 | 65.14 |
|   Paper pack  |  12.3 |  16.7 |
|     Metal     |  7.13 |  9.56 |
|     Glass     | 11.05 | 15.15 |
|    Plastic    | 14.41 | 19.66 |
|   Styrofoam   | 26.02 | 36.89 |
|  Plastic bag  | 57.15 | 77.72 |
|    Battery    |  0.0  |  0.0  |
|    Clothing   |  8.37 |  9.57 |
+---------------+-------+-------+
2021-10-25 04:31:39,416 - mmseg - INFO - Summary:
2021-10-25 04:31:39,417 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 84.31 | 27.15 | 34.19 |
+-------+-------+-------+
2021-10-25 04:31:39,420 - mmseg - INFO - Exp name: UperCSwinT.py
2021-10-25 04:31:39,420 - mmseg - INFO - Epoch(val) [16][655]	aAcc: 0.8431, mIoU: 0.2715, mAcc: 0.3419, IoU.Background: 0.8898, IoU.General trash: 0.2284, IoU.Paper: 0.5042, IoU.Paper pack: 0.1230, IoU.Metal: 0.0713, IoU.Glass: 0.1105, IoU.Plastic: 0.1441, IoU.Styrofoam: 0.2602, IoU.Plastic bag: 0.5715, IoU.Battery: 0.0000, IoU.Clothing: 0.0837, Acc.Background: 0.9615, Acc.General trash: 0.2958, Acc.Paper: 0.6514, Acc.Paper pack: 0.1670, Acc.Metal: 0.0956, Acc.Glass: 0.1515, Acc.Plastic: 0.1966, Acc.Styrofoam: 0.3689, Acc.Plastic bag: 0.7772, Acc.Battery: 0.0000, Acc.Clothing: 0.0957
2021-10-25 04:32:04,793 - mmseg - INFO - Epoch [17][10/163]	lr: 9.550e-06, eta: 0:23:52, time: 2.536, data_time: 0.288, memory: 29235, decode.loss_ce: 0.4187, decode.acc_seg: 86.5203, aux.loss_ce: 0.2103, aux.acc_seg: 83.4874, loss: 0.6290, grad_norm: 2.2645
2021-10-25 04:32:27,319 - mmseg - INFO - Epoch [17][20/163]	lr: 9.550e-06, eta: 0:23:30, time: 2.253, data_time: 0.011, memory: 29235, decode.loss_ce: 0.3969, decode.acc_seg: 87.7793, aux.loss_ce: 0.2030, aux.acc_seg: 84.8482, loss: 0.5999, grad_norm: 2.2265
2021-10-25 04:32:49,853 - mmseg - INFO - Epoch [17][30/163]	lr: 9.550e-06, eta: 0:23:07, time: 2.253, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4271, decode.acc_seg: 86.1337, aux.loss_ce: 0.2265, aux.acc_seg: 82.2164, loss: 0.6536, grad_norm: 2.2427
2021-10-25 04:33:12,362 - mmseg - INFO - Epoch [17][40/163]	lr: 9.550e-06, eta: 0:22:45, time: 2.251, data_time: 0.011, memory: 29235, decode.loss_ce: 0.4194, decode.acc_seg: 86.5485, aux.loss_ce: 0.2058, aux.acc_seg: 84.6093, loss: 0.6251, grad_norm: 2.2940
2021-10-25 04:33:34,868 - mmseg - INFO - Epoch [17][50/163]	lr: 9.550e-06, eta: 0:22:23, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.3881, decode.acc_seg: 88.1693, aux.loss_ce: 0.1939, aux.acc_seg: 85.3537, loss: 0.5821, grad_norm: 2.0396
2021-10-25 04:33:57,386 - mmseg - INFO - Epoch [17][60/163]	lr: 9.550e-06, eta: 0:22:01, time: 2.252, data_time: 0.011, memory: 29235, decode.loss_ce: 0.4603, decode.acc_seg: 85.5864, aux.loss_ce: 0.2243, aux.acc_seg: 83.2608, loss: 0.6846, grad_norm: 2.6960
2021-10-25 04:34:19,881 - mmseg - INFO - Epoch [17][70/163]	lr: 9.550e-06, eta: 0:21:38, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.3709, decode.acc_seg: 88.2490, aux.loss_ce: 0.1853, aux.acc_seg: 85.9307, loss: 0.5562, grad_norm: 2.2103
2021-10-25 04:34:42,369 - mmseg - INFO - Epoch [17][80/163]	lr: 9.550e-06, eta: 0:21:16, time: 2.249, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4466, decode.acc_seg: 85.7123, aux.loss_ce: 0.2281, aux.acc_seg: 81.7388, loss: 0.6747, grad_norm: 2.3864
2021-10-25 04:35:04,895 - mmseg - INFO - Epoch [17][90/163]	lr: 9.550e-06, eta: 0:20:54, time: 2.253, data_time: 0.010, memory: 29235, decode.loss_ce: 0.3944, decode.acc_seg: 87.5360, aux.loss_ce: 0.2070, aux.acc_seg: 84.4889, loss: 0.6014, grad_norm: 2.3440
2021-10-25 04:35:27,411 - mmseg - INFO - Epoch [17][100/163]	lr: 9.550e-06, eta: 0:20:32, time: 2.252, data_time: 0.011, memory: 29235, decode.loss_ce: 0.4263, decode.acc_seg: 86.9246, aux.loss_ce: 0.2104, aux.acc_seg: 84.0066, loss: 0.6367, grad_norm: 1.9787
2021-10-25 04:35:49,911 - mmseg - INFO - Epoch [17][110/163]	lr: 9.550e-06, eta: 0:20:09, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4541, decode.acc_seg: 85.7058, aux.loss_ce: 0.2357, aux.acc_seg: 81.8145, loss: 0.6898, grad_norm: 2.4897
2021-10-25 04:36:12,491 - mmseg - INFO - Epoch [17][120/163]	lr: 9.550e-06, eta: 0:19:47, time: 2.258, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4022, decode.acc_seg: 87.3095, aux.loss_ce: 0.2056, aux.acc_seg: 84.5911, loss: 0.6078, grad_norm: 2.4366
2021-10-25 04:36:34,995 - mmseg - INFO - Epoch [17][130/163]	lr: 9.550e-06, eta: 0:19:25, time: 2.250, data_time: 0.011, memory: 29235, decode.loss_ce: 0.4355, decode.acc_seg: 86.3419, aux.loss_ce: 0.2177, aux.acc_seg: 83.6062, loss: 0.6532, grad_norm: 2.5133
2021-10-25 04:36:57,489 - mmseg - INFO - Epoch [17][140/163]	lr: 9.550e-06, eta: 0:19:02, time: 2.249, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4191, decode.acc_seg: 86.7925, aux.loss_ce: 0.2156, aux.acc_seg: 83.2876, loss: 0.6347, grad_norm: 2.3686
2021-10-25 04:37:19,981 - mmseg - INFO - Epoch [17][150/163]	lr: 9.550e-06, eta: 0:18:40, time: 2.249, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4177, decode.acc_seg: 86.8738, aux.loss_ce: 0.2036, aux.acc_seg: 84.3820, loss: 0.6212, grad_norm: 2.1183
2021-10-25 04:37:42,450 - mmseg - INFO - Epoch [17][160/163]	lr: 9.550e-06, eta: 0:18:18, time: 2.247, data_time: 0.010, memory: 29235, decode.loss_ce: 0.3993, decode.acc_seg: 87.4901, aux.loss_ce: 0.2087, aux.acc_seg: 84.3707, loss: 0.6079, grad_norm: 2.3460
2021-10-25 04:38:44,972 - mmseg - INFO - per class results:
2021-10-25 04:38:44,973 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|   Background  | 89.16 | 96.97 |
| General trash | 26.85 | 38.98 |
|     Paper     | 50.82 | 69.02 |
|   Paper pack  | 11.37 |  13.6 |
|     Metal     |  7.21 | 10.01 |
|     Glass     |  8.63 | 11.86 |
|    Plastic    | 17.62 | 26.04 |
|   Styrofoam   |  22.5 | 28.15 |
|  Plastic bag  | 57.53 |  70.1 |
|    Battery    |  0.0  |  0.0  |
|    Clothing   |  5.21 |  6.75 |
+---------------+-------+-------+
2021-10-25 04:38:44,973 - mmseg - INFO - Summary:
2021-10-25 04:38:44,974 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 84.51 | 26.99 | 33.77 |
+-------+-------+-------+
2021-10-25 04:38:44,977 - mmseg - INFO - Exp name: UperCSwinT.py
2021-10-25 04:38:44,977 - mmseg - INFO - Epoch(val) [17][655]	aAcc: 0.8451, mIoU: 0.2699, mAcc: 0.3377, IoU.Background: 0.8916, IoU.General trash: 0.2685, IoU.Paper: 0.5082, IoU.Paper pack: 0.1137, IoU.Metal: 0.0721, IoU.Glass: 0.0863, IoU.Plastic: 0.1762, IoU.Styrofoam: 0.2250, IoU.Plastic bag: 0.5753, IoU.Battery: 0.0000, IoU.Clothing: 0.0521, Acc.Background: 0.9697, Acc.General trash: 0.3898, Acc.Paper: 0.6902, Acc.Paper pack: 0.1360, Acc.Metal: 0.1001, Acc.Glass: 0.1186, Acc.Plastic: 0.2604, Acc.Styrofoam: 0.2815, Acc.Plastic bag: 0.7010, Acc.Battery: 0.0000, Acc.Clothing: 0.0675
2021-10-25 04:39:10,651 - mmseg - INFO - Epoch [18][10/163]	lr: 5.450e-06, eta: 0:17:48, time: 2.566, data_time: 0.322, memory: 29235, decode.loss_ce: 0.4050, decode.acc_seg: 87.1158, aux.loss_ce: 0.2136, aux.acc_seg: 83.1835, loss: 0.6186, grad_norm: 2.7392
2021-10-25 04:39:33,207 - mmseg - INFO - Epoch [18][20/163]	lr: 5.450e-06, eta: 0:17:26, time: 2.256, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4143, decode.acc_seg: 87.3559, aux.loss_ce: 0.2071, aux.acc_seg: 84.0734, loss: 0.6215, grad_norm: 2.1835
2021-10-25 04:39:55,738 - mmseg - INFO - Epoch [18][30/163]	lr: 5.450e-06, eta: 0:17:04, time: 2.253, data_time: 0.010, memory: 29235, decode.loss_ce: 0.3705, decode.acc_seg: 88.1345, aux.loss_ce: 0.1952, aux.acc_seg: 85.4094, loss: 0.5657, grad_norm: 2.2099
2021-10-25 04:40:18,271 - mmseg - INFO - Epoch [18][40/163]	lr: 5.450e-06, eta: 0:16:41, time: 2.253, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4227, decode.acc_seg: 86.7899, aux.loss_ce: 0.2146, aux.acc_seg: 83.4979, loss: 0.6373, grad_norm: 2.0116
2021-10-25 04:40:40,790 - mmseg - INFO - Epoch [18][50/163]	lr: 5.450e-06, eta: 0:16:19, time: 2.252, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4098, decode.acc_seg: 86.9560, aux.loss_ce: 0.2102, aux.acc_seg: 84.4260, loss: 0.6200, grad_norm: 2.3000
2021-10-25 04:41:03,297 - mmseg - INFO - Epoch [18][60/163]	lr: 5.450e-06, eta: 0:15:57, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4014, decode.acc_seg: 87.9794, aux.loss_ce: 0.2043, aux.acc_seg: 84.5203, loss: 0.6058, grad_norm: 2.2953
2021-10-25 04:41:25,810 - mmseg - INFO - Epoch [18][70/163]	lr: 5.450e-06, eta: 0:15:35, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4306, decode.acc_seg: 86.6356, aux.loss_ce: 0.2194, aux.acc_seg: 83.1775, loss: 0.6500, grad_norm: 2.0599
2021-10-25 04:41:48,321 - mmseg - INFO - Epoch [18][80/163]	lr: 5.450e-06, eta: 0:15:12, time: 2.251, data_time: 0.012, memory: 29235, decode.loss_ce: 0.3858, decode.acc_seg: 87.8866, aux.loss_ce: 0.1985, aux.acc_seg: 84.6265, loss: 0.5843, grad_norm: 2.4672
2021-10-25 04:42:10,816 - mmseg - INFO - Epoch [18][90/163]	lr: 5.450e-06, eta: 0:14:50, time: 2.250, data_time: 0.011, memory: 29235, decode.loss_ce: 0.4069, decode.acc_seg: 87.9691, aux.loss_ce: 0.2099, aux.acc_seg: 84.1882, loss: 0.6167, grad_norm: 2.0188
2021-10-25 04:42:33,307 - mmseg - INFO - Epoch [18][100/163]	lr: 5.450e-06, eta: 0:14:28, time: 2.249, data_time: 0.011, memory: 29235, decode.loss_ce: 0.3637, decode.acc_seg: 88.9856, aux.loss_ce: 0.1876, aux.acc_seg: 85.7454, loss: 0.5512, grad_norm: 1.9596
2021-10-25 04:42:55,802 - mmseg - INFO - Epoch [18][110/163]	lr: 5.450e-06, eta: 0:14:05, time: 2.249, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4065, decode.acc_seg: 86.9607, aux.loss_ce: 0.2066, aux.acc_seg: 83.7418, loss: 0.6131, grad_norm: 2.3606
2021-10-25 04:43:18,312 - mmseg - INFO - Epoch [18][120/163]	lr: 5.450e-06, eta: 0:13:43, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4254, decode.acc_seg: 86.4950, aux.loss_ce: 0.2167, aux.acc_seg: 83.6969, loss: 0.6422, grad_norm: 2.2812
2021-10-25 04:43:40,816 - mmseg - INFO - Epoch [18][130/163]	lr: 5.450e-06, eta: 0:13:21, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.3914, decode.acc_seg: 88.2170, aux.loss_ce: 0.2047, aux.acc_seg: 84.3338, loss: 0.5961, grad_norm: 2.0922
2021-10-25 04:44:03,345 - mmseg - INFO - Epoch [18][140/163]	lr: 5.450e-06, eta: 0:12:59, time: 2.253, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4138, decode.acc_seg: 86.6273, aux.loss_ce: 0.2111, aux.acc_seg: 83.2977, loss: 0.6248, grad_norm: 2.5688
2021-10-25 04:44:25,864 - mmseg - INFO - Epoch [18][150/163]	lr: 5.450e-06, eta: 0:12:36, time: 2.252, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4575, decode.acc_seg: 85.3434, aux.loss_ce: 0.2336, aux.acc_seg: 82.2598, loss: 0.6911, grad_norm: 2.3381
2021-10-25 04:44:48,337 - mmseg - INFO - Epoch [18][160/163]	lr: 5.450e-06, eta: 0:12:14, time: 2.247, data_time: 0.010, memory: 29235, decode.loss_ce: 0.3992, decode.acc_seg: 87.4933, aux.loss_ce: 0.2097, aux.acc_seg: 83.5764, loss: 0.6089, grad_norm: 2.2129
2021-10-25 04:45:50,779 - mmseg - INFO - per class results:
2021-10-25 04:45:50,781 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|   Background  | 89.21 | 96.59 |
| General trash | 25.65 | 35.13 |
|     Paper     | 51.13 | 68.84 |
|   Paper pack  | 11.58 | 14.59 |
|     Metal     |  9.1  | 13.09 |
|     Glass     | 12.81 | 19.75 |
|    Plastic    | 14.55 |  20.2 |
|   Styrofoam   | 26.48 | 36.22 |
|  Plastic bag  | 57.58 | 72.51 |
|    Battery    |  0.0  |  0.0  |
|    Clothing   |  5.01 |  5.94 |
+---------------+-------+-------+
2021-10-25 04:45:50,781 - mmseg - INFO - Summary:
2021-10-25 04:45:50,781 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 84.51 | 27.55 | 34.81 |
+-------+-------+-------+
2021-10-25 04:45:52,326 - mmseg - INFO - Now best checkpoint is saved as best_mIoU_epoch_18.pth.
2021-10-25 04:45:52,326 - mmseg - INFO - Best mIoU is 0.2755 at 18 epoch.
2021-10-25 04:45:52,330 - mmseg - INFO - Exp name: UperCSwinT.py
2021-10-25 04:45:52,330 - mmseg - INFO - Epoch(val) [18][655]	aAcc: 0.8451, mIoU: 0.2755, mAcc: 0.3481, IoU.Background: 0.8921, IoU.General trash: 0.2565, IoU.Paper: 0.5113, IoU.Paper pack: 0.1158, IoU.Metal: 0.0910, IoU.Glass: 0.1281, IoU.Plastic: 0.1455, IoU.Styrofoam: 0.2648, IoU.Plastic bag: 0.5758, IoU.Battery: 0.0000, IoU.Clothing: 0.0501, Acc.Background: 0.9659, Acc.General trash: 0.3513, Acc.Paper: 0.6884, Acc.Paper pack: 0.1459, Acc.Metal: 0.1309, Acc.Glass: 0.1975, Acc.Plastic: 0.2020, Acc.Styrofoam: 0.3622, Acc.Plastic bag: 0.7251, Acc.Battery: 0.0000, Acc.Clothing: 0.0594
2021-10-25 04:46:17,814 - mmseg - INFO - Epoch [19][10/163]	lr: 2.448e-06, eta: 0:11:44, time: 2.547, data_time: 0.296, memory: 29235, decode.loss_ce: 0.4140, decode.acc_seg: 86.9762, aux.loss_ce: 0.2092, aux.acc_seg: 84.4543, loss: 0.6232, grad_norm: 2.3412
2021-10-25 04:46:40,372 - mmseg - INFO - Epoch [19][20/163]	lr: 2.448e-06, eta: 0:11:22, time: 2.256, data_time: 0.011, memory: 29235, decode.loss_ce: 0.4110, decode.acc_seg: 86.9729, aux.loss_ce: 0.2093, aux.acc_seg: 83.6787, loss: 0.6203, grad_norm: 2.5703
2021-10-25 04:47:02,879 - mmseg - INFO - Epoch [19][30/163]	lr: 2.448e-06, eta: 0:11:00, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.3903, decode.acc_seg: 88.5380, aux.loss_ce: 0.2068, aux.acc_seg: 83.9375, loss: 0.5971, grad_norm: 2.4283
2021-10-25 04:47:25,396 - mmseg - INFO - Epoch [19][40/163]	lr: 2.448e-06, eta: 0:10:38, time: 2.252, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4379, decode.acc_seg: 85.5904, aux.loss_ce: 0.2316, aux.acc_seg: 81.3561, loss: 0.6695, grad_norm: 2.3484
2021-10-25 04:47:47,917 - mmseg - INFO - Epoch [19][50/163]	lr: 2.448e-06, eta: 0:10:15, time: 2.252, data_time: 0.011, memory: 29235, decode.loss_ce: 0.3827, decode.acc_seg: 88.4967, aux.loss_ce: 0.1988, aux.acc_seg: 85.2669, loss: 0.5815, grad_norm: 2.3358
2021-10-25 04:48:10,404 - mmseg - INFO - Epoch [19][60/163]	lr: 2.448e-06, eta: 0:09:53, time: 2.249, data_time: 0.011, memory: 29235, decode.loss_ce: 0.4094, decode.acc_seg: 87.4959, aux.loss_ce: 0.2075, aux.acc_seg: 85.4832, loss: 0.6168, grad_norm: 2.3798
2021-10-25 04:48:32,895 - mmseg - INFO - Epoch [19][70/163]	lr: 2.448e-06, eta: 0:09:31, time: 2.249, data_time: 0.010, memory: 29235, decode.loss_ce: 0.3974, decode.acc_seg: 87.4896, aux.loss_ce: 0.2100, aux.acc_seg: 83.7017, loss: 0.6075, grad_norm: 2.3027
2021-10-25 04:48:55,389 - mmseg - INFO - Epoch [19][80/163]	lr: 2.448e-06, eta: 0:09:08, time: 2.249, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4128, decode.acc_seg: 86.7241, aux.loss_ce: 0.2090, aux.acc_seg: 84.2387, loss: 0.6218, grad_norm: 2.5007
2021-10-25 04:49:17,897 - mmseg - INFO - Epoch [19][90/163]	lr: 2.448e-06, eta: 0:08:46, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4227, decode.acc_seg: 86.4116, aux.loss_ce: 0.2246, aux.acc_seg: 82.7066, loss: 0.6473, grad_norm: 2.7295
2021-10-25 04:49:40,397 - mmseg - INFO - Epoch [19][100/163]	lr: 2.448e-06, eta: 0:08:24, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4247, decode.acc_seg: 86.1497, aux.loss_ce: 0.2133, aux.acc_seg: 83.6233, loss: 0.6380, grad_norm: 2.2344
2021-10-25 04:50:02,895 - mmseg - INFO - Epoch [19][110/163]	lr: 2.448e-06, eta: 0:08:02, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4183, decode.acc_seg: 86.9813, aux.loss_ce: 0.2106, aux.acc_seg: 84.4268, loss: 0.6289, grad_norm: 2.2676
2021-10-25 04:50:25,396 - mmseg - INFO - Epoch [19][120/163]	lr: 2.448e-06, eta: 0:07:39, time: 2.250, data_time: 0.010, memory: 29235, decode.loss_ce: 0.3775, decode.acc_seg: 88.2566, aux.loss_ce: 0.1963, aux.acc_seg: 85.0709, loss: 0.5738, grad_norm: 2.2958
2021-10-25 04:50:47,909 - mmseg - INFO - Epoch [19][130/163]	lr: 2.448e-06, eta: 0:07:17, time: 2.251, data_time: 0.011, memory: 29235, decode.loss_ce: 0.3885, decode.acc_seg: 88.0389, aux.loss_ce: 0.1986, aux.acc_seg: 84.9574, loss: 0.5870, grad_norm: 2.2690
2021-10-25 04:51:10,400 - mmseg - INFO - Epoch [19][140/163]	lr: 2.448e-06, eta: 0:06:55, time: 2.249, data_time: 0.010, memory: 29235, decode.loss_ce: 0.3675, decode.acc_seg: 88.4580, aux.loss_ce: 0.1939, aux.acc_seg: 85.3009, loss: 0.5614, grad_norm: 1.9310
2021-10-25 04:51:32,916 - mmseg - INFO - Epoch [19][150/163]	lr: 2.448e-06, eta: 0:06:32, time: 2.252, data_time: 0.011, memory: 29235, decode.loss_ce: 0.4006, decode.acc_seg: 87.9913, aux.loss_ce: 0.2097, aux.acc_seg: 84.9208, loss: 0.6103, grad_norm: 2.0899
2021-10-25 04:51:55,393 - mmseg - INFO - Epoch [19][160/163]	lr: 2.448e-06, eta: 0:06:10, time: 2.248, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4134, decode.acc_seg: 86.8286, aux.loss_ce: 0.2182, aux.acc_seg: 82.8491, loss: 0.6316, grad_norm: 2.5825
2021-10-25 04:52:56,671 - mmseg - INFO - per class results:
2021-10-25 04:52:56,672 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|   Background  | 89.24 | 96.67 |
| General trash | 25.16 | 33.86 |
|     Paper     | 51.22 | 68.12 |
|   Paper pack  | 12.83 | 16.78 |
|     Metal     |  7.94 | 11.32 |
|     Glass     | 13.94 | 21.23 |
|    Plastic    | 14.99 | 20.77 |
|   Styrofoam   | 24.38 | 33.12 |
|  Plastic bag  | 57.88 | 73.63 |
|    Battery    |  0.0  |  0.0  |
|    Clothing   |  4.52 |  4.98 |
+---------------+-------+-------+
2021-10-25 04:52:56,672 - mmseg - INFO - Summary:
2021-10-25 04:52:56,673 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 84.58 | 27.46 | 34.59 |
+-------+-------+-------+
2021-10-25 04:52:56,676 - mmseg - INFO - Exp name: UperCSwinT.py
2021-10-25 04:52:56,676 - mmseg - INFO - Epoch(val) [19][655]	aAcc: 0.8458, mIoU: 0.2746, mAcc: 0.3459, IoU.Background: 0.8924, IoU.General trash: 0.2516, IoU.Paper: 0.5122, IoU.Paper pack: 0.1283, IoU.Metal: 0.0794, IoU.Glass: 0.1394, IoU.Plastic: 0.1499, IoU.Styrofoam: 0.2438, IoU.Plastic bag: 0.5788, IoU.Battery: 0.0000, IoU.Clothing: 0.0452, Acc.Background: 0.9667, Acc.General trash: 0.3386, Acc.Paper: 0.6812, Acc.Paper pack: 0.1678, Acc.Metal: 0.1132, Acc.Glass: 0.2123, Acc.Plastic: 0.2077, Acc.Styrofoam: 0.3312, Acc.Plastic bag: 0.7363, Acc.Battery: 0.0000, Acc.Clothing: 0.0498
2021-10-25 04:53:22,428 - mmseg - INFO - Epoch [20][10/163]	lr: 6.163e-07, eta: 0:05:41, time: 2.574, data_time: 0.326, memory: 29235, decode.loss_ce: 0.3840, decode.acc_seg: 88.2227, aux.loss_ce: 0.2035, aux.acc_seg: 84.2241, loss: 0.5875, grad_norm: 2.5044
2021-10-25 04:53:44,919 - mmseg - INFO - Epoch [20][20/163]	lr: 6.163e-07, eta: 0:05:19, time: 2.249, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4458, decode.acc_seg: 85.5441, aux.loss_ce: 0.2368, aux.acc_seg: 81.4337, loss: 0.6826, grad_norm: 2.4605
2021-10-25 04:54:07,408 - mmseg - INFO - Epoch [20][30/163]	lr: 6.163e-07, eta: 0:04:56, time: 2.249, data_time: 0.011, memory: 29235, decode.loss_ce: 0.3662, decode.acc_seg: 88.6597, aux.loss_ce: 0.1881, aux.acc_seg: 85.9569, loss: 0.5543, grad_norm: 2.0946
2021-10-25 04:54:29,883 - mmseg - INFO - Epoch [20][40/163]	lr: 6.163e-07, eta: 0:04:34, time: 2.247, data_time: 0.011, memory: 29235, decode.loss_ce: 0.4163, decode.acc_seg: 86.5595, aux.loss_ce: 0.2227, aux.acc_seg: 82.5628, loss: 0.6390, grad_norm: 2.3395
2021-10-25 04:54:52,374 - mmseg - INFO - Epoch [20][50/163]	lr: 6.163e-07, eta: 0:04:12, time: 2.249, data_time: 0.010, memory: 29235, decode.loss_ce: 0.3925, decode.acc_seg: 87.7024, aux.loss_ce: 0.1994, aux.acc_seg: 84.5422, loss: 0.5919, grad_norm: 2.4717
2021-10-25 04:55:14,872 - mmseg - INFO - Epoch [20][60/163]	lr: 6.163e-07, eta: 0:03:49, time: 2.250, data_time: 0.011, memory: 29235, decode.loss_ce: 0.4011, decode.acc_seg: 87.4574, aux.loss_ce: 0.2091, aux.acc_seg: 84.2548, loss: 0.6102, grad_norm: 2.2088
2021-10-25 04:55:37,401 - mmseg - INFO - Epoch [20][70/163]	lr: 6.163e-07, eta: 0:03:27, time: 2.253, data_time: 0.010, memory: 29235, decode.loss_ce: 0.3969, decode.acc_seg: 87.2669, aux.loss_ce: 0.2155, aux.acc_seg: 83.3289, loss: 0.6124, grad_norm: 2.3726
2021-10-25 04:55:59,913 - mmseg - INFO - Epoch [20][80/163]	lr: 6.163e-07, eta: 0:03:05, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.3911, decode.acc_seg: 87.5993, aux.loss_ce: 0.2126, aux.acc_seg: 83.5450, loss: 0.6037, grad_norm: 2.4379
2021-10-25 04:56:22,391 - mmseg - INFO - Epoch [20][90/163]	lr: 6.163e-07, eta: 0:02:42, time: 2.248, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4321, decode.acc_seg: 87.0261, aux.loss_ce: 0.2213, aux.acc_seg: 83.3126, loss: 0.6533, grad_norm: 2.4585
2021-10-25 04:56:44,904 - mmseg - INFO - Epoch [20][100/163]	lr: 6.163e-07, eta: 0:02:20, time: 2.251, data_time: 0.010, memory: 29235, decode.loss_ce: 0.3857, decode.acc_seg: 87.9358, aux.loss_ce: 0.2007, aux.acc_seg: 84.6524, loss: 0.5865, grad_norm: 2.0811
2021-10-25 04:57:07,399 - mmseg - INFO - Epoch [20][110/163]	lr: 6.163e-07, eta: 0:01:58, time: 2.249, data_time: 0.010, memory: 29235, decode.loss_ce: 0.3721, decode.acc_seg: 88.5663, aux.loss_ce: 0.2025, aux.acc_seg: 84.6444, loss: 0.5746, grad_norm: 2.1185
2021-10-25 04:57:29,996 - mmseg - INFO - Epoch [20][120/163]	lr: 6.163e-07, eta: 0:01:35, time: 2.260, data_time: 0.010, memory: 29235, decode.loss_ce: 0.3844, decode.acc_seg: 88.0117, aux.loss_ce: 0.2085, aux.acc_seg: 84.2283, loss: 0.5929, grad_norm: 2.3550
2021-10-25 04:57:52,498 - mmseg - INFO - Epoch [20][130/163]	lr: 6.163e-07, eta: 0:01:13, time: 2.250, data_time: 0.011, memory: 29235, decode.loss_ce: 0.3806, decode.acc_seg: 88.2192, aux.loss_ce: 0.1980, aux.acc_seg: 85.1117, loss: 0.5786, grad_norm: 2.3725
2021-10-25 04:58:14,981 - mmseg - INFO - Epoch [20][140/163]	lr: 6.163e-07, eta: 0:00:51, time: 2.248, data_time: 0.010, memory: 29235, decode.loss_ce: 0.4096, decode.acc_seg: 87.1815, aux.loss_ce: 0.2112, aux.acc_seg: 83.9841, loss: 0.6207, grad_norm: 2.5744
2021-10-25 04:58:37,471 - mmseg - INFO - Epoch [20][150/163]	lr: 6.163e-07, eta: 0:00:29, time: 2.249, data_time: 0.011, memory: 29235, decode.loss_ce: 0.3750, decode.acc_seg: 88.4561, aux.loss_ce: 0.1929, aux.acc_seg: 85.3954, loss: 0.5679, grad_norm: 2.0912
2021-10-25 04:58:59,954 - mmseg - INFO - Epoch [20][160/163]	lr: 6.163e-07, eta: 0:00:06, time: 2.248, data_time: 0.010, memory: 29235, decode.loss_ce: 0.3790, decode.acc_seg: 87.8757, aux.loss_ce: 0.1932, aux.acc_seg: 85.2271, loss: 0.5722, grad_norm: 2.0082
2021-10-25 04:59:06,777 - mmseg - INFO - Saving checkpoint at 20 epochs
2021-10-25 05:00:04,353 - mmseg - INFO - per class results:
2021-10-25 05:00:04,354 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|   Background  | 89.27 | 96.61 |
| General trash | 25.49 | 35.61 |
|     Paper     | 51.35 | 67.93 |
|   Paper pack  | 12.15 | 15.55 |
|     Metal     |  7.62 | 11.08 |
|     Glass     | 14.34 | 22.68 |
|    Plastic    | 14.78 |  20.3 |
|   Styrofoam   | 25.43 | 35.19 |
|  Plastic bag  | 57.96 | 73.55 |
|    Battery    |  0.0  |  0.0  |
|    Clothing   |  4.63 |  5.23 |
+---------------+-------+-------+
2021-10-25 05:00:04,354 - mmseg - INFO - Summary:
2021-10-25 05:00:04,355 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 84.57 | 27.55 | 34.88 |
+-------+-------+-------+
2021-10-25 05:00:04,358 - mmseg - INFO - Exp name: UperCSwinT.py
2021-10-25 05:00:04,358 - mmseg - INFO - Epoch(val) [20][655]	aAcc: 0.8457, mIoU: 0.2755, mAcc: 0.3488, IoU.Background: 0.8927, IoU.General trash: 0.2549, IoU.Paper: 0.5135, IoU.Paper pack: 0.1215, IoU.Metal: 0.0762, IoU.Glass: 0.1434, IoU.Plastic: 0.1478, IoU.Styrofoam: 0.2543, IoU.Plastic bag: 0.5796, IoU.Battery: 0.0000, IoU.Clothing: 0.0463, Acc.Background: 0.9661, Acc.General trash: 0.3561, Acc.Paper: 0.6793, Acc.Paper pack: 0.1555, Acc.Metal: 0.1108, Acc.Glass: 0.2268, Acc.Plastic: 0.2030, Acc.Styrofoam: 0.3519, Acc.Plastic bag: 0.7355, Acc.Battery: 0.0000, Acc.Clothing: 0.0523
