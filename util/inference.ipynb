{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94257f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "import torch\n",
    "from mmcv.parallel import MMDataParallel, MMDistributedDataParallel\n",
    "from mmcv.runner import (get_dist_info, init_dist, load_checkpoint,\n",
    "                         wrap_fp16_model)\n",
    "from mmcv.utils import DictAction\n",
    "from mmcv import Config\n",
    "from mmseg.apis import multi_gpu_test, single_gpu_test\n",
    "from mmseg.datasets import build_dataloader, build_dataset\n",
    "from mmseg.models import build_segmentor\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "from mmcv import Config\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79d30117",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'OCR_swinB_aux.py' # model config 경로\n",
    "PATH = '/opt/ml/segmentation/moon/mmsegmentation/work_dirs/OCR_swinB_aux' # 모델 저장된 폴더\n",
    "BEST_CHECKPOINT = glob(os.path.join(PATH,'best_*'))\n",
    "assert len(BEST_CHECKPOINT)==1\n",
    "BEST_CHECKPOINT = BEST_CHECKPOINT[0]\n",
    "# EPOCH ='best_mIoU_epoch_39.pth' # model checkpoint 파일이름\n",
    "\n",
    "cfg =Config.fromfile(os.path.join(PATH,MODEL))\n",
    "cfg.data.test.test_mode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cc53dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_min = 512\n",
    "size_max = 1024\n",
    "multi_scale_list = [(x,x) for x in range(size_min, size_max+1, 128)]\n",
    "cfg.data.test.pipeline[1]['img_scale'] = multi_scale_list # Resize\n",
    "cfg.data.test.pipeline[1]['flip']=True\n",
    "cfg.data.test.img_dir = 'images/test'\n",
    "cfg.data.test.ann_dir = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecdbe939",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-20 13:30:32,309 - mmseg - INFO - Loaded 819 images\n"
     ]
    }
   ],
   "source": [
    "test_dataset = build_dataset(cfg.data.test)\n",
    "test_loader = build_dataloader(\n",
    "        test_dataset,\n",
    "        samples_per_gpu=1,\n",
    "        workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "        dist=False,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60781437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use load_from_local loader\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "cfg.model.pretrained = None\n",
    "cfg.model.train_cfg = None\n",
    "\n",
    "checkpoint_path = BEST_CHECKPOINT\n",
    "\n",
    "model = build_segmentor(cfg.model, test_cfg=cfg.get('test_cfg'))\n",
    "checkpoint = load_checkpoint(model, checkpoint_path, map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7c19299",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.CLASSES = checkpoint['meta']['CLASSES']\n",
    "model.PALETTE = checkpoint['meta']['PALETTE']\n",
    "model = MMDataParallel(model.cuda(), device_ids=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7347fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                               ] 12/819, 0.3 task/s, elapsed: 37s, ETA:  2492s"
     ]
    }
   ],
   "source": [
    "output = single_gpu_test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba3191f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "819it [05:53,  2.31it/s]\n"
     ]
    }
   ],
   "source": [
    "size = 256\n",
    "transform = A.Compose([A.Resize(size, size)])\n",
    "\n",
    "file_name_list=[]\n",
    "preds_array = np.empty((0,size*size),dtype=np.int64)\n",
    "img_infos = test_dataset.img_infos\n",
    "\n",
    "for idx,out in tqdm(enumerate(output)):\n",
    "    image = np.zeros((1,size,size))\n",
    "    transformed = transform(image=image,mask=out)\n",
    "    mask = transformed['mask']\n",
    "    \n",
    "    mask = mask.reshape(-1,size*size).astype(int)\n",
    "    preds_array = np.vstack((preds_array,mask))\n",
    "    \n",
    "    file_name_list.append(img_infos[idx]['filename'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4349365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_submisson.csv 열기\n",
    "tmp_submission = pd.read_csv('/opt/ml/segmentation/baseline_code/submission/sample_submission.csv', index_col=None)\n",
    "\n",
    "# PredictionString 대입\n",
    "for file_name, string in zip(file_name_list, preds_array):\n",
    "    file_name = '/'.join(file_name.split('+'))\n",
    "    tmp_submission = tmp_submission.append({\"image_id\" : file_name, \"PredictionString\" : ' '.join(str(e) for e in string.tolist())}, \n",
    "                                   ignore_index=True)\n",
    "\n",
    "# submission.csv로 저장\n",
    "\n",
    "# 순서도 같아야 채점이 되기 때문에 sample_submission이 필요\n",
    "sample = pd.read_csv('/opt/ml/segmentation/moon/submission/sample_submission.csv', index_col=None)\n",
    "submission = pd.read_csv('/opt/ml/segmentation/baseline_code/submission/sample_submission.csv', index_col=None)\n",
    "for image_id in sample['image_id'].tolist():\n",
    "    prediction_string = tmp_submission[tmp_submission['image_id']==image_id]['PredictionString'].iloc[0]\n",
    "    submission = submission.append({\"image_id\" : image_id, \"PredictionString\" : prediction_string }, \n",
    "                                   ignore_index=True)\n",
    "\n",
    "# submission.csv로 저장\n",
    "submission.to_csv(f\"./submission/{MODEL.split('.')[0]}_TTA.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427b648a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbf5d4d",
   "metadata": {},
   "source": [
    "# Pseudo Labeling\n",
    "- submission을 기반으로 할 경우, 256x256을 upssampling해야하기 때문에 output을 기반으로 pseudo labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5586f368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5e7a5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_path = '/opt/ml/segmentation/moon/dataset/annotations/pseudo/'\n",
    "img_infos = test_dataset.img_infos\n",
    "file_names = [img_info['filename'] for img_info in img_infos]\n",
    "for file_name,img in zip(file_names,output):\n",
    "    file_path = os.path.join(pseudo_path,file_name)\n",
    "    cv2.imwrite(file_path,img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2411d9d2",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmseg",
   "language": "python",
   "name": "mmseg"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
